% ymrrun-masterMCMC.Snw - just doing MCMC output (MCMC lines were 
%  commented out in ymrrun-masterMCMC.Snw). AME, 3rd May 2011
% ymrrun5-0.Snw. 5/4/11.
% ymrrun2-5.Snw - from Rowan's run2 output. Fifth reweighting. Also
%  adding in automatic table of parameter values. 28th March 2011
% ymrrun1dos.Snw - automatically plot MPD output from Awatea, using
%  scape. Awatea results.dat file must be in directory above, this
%  one used just for figures. 23rd Feburary 2011

\documentclass[12pt]{article}

\usepackage{Sweave}   % andy add3ed
\usepackage{epsfig}
\usepackage{rotating}    % for sideways table
\usepackage{longtable}
% \usepackage{placeins}
% \usepackage{nccmath}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry} 


\newcommand{\eb}{\begin{eqnarray}}
\newcommand{\ee}{\end{eqnarray}}
\renewcommand{\baselinestretch}{1.0}
\newcommand{\Bmsy}{B_\mathrm{MSY}}

% For write up
\def\AppLet{G}                   % Appendix letter
\def\StartP{100}                   % page start

\renewcommand{\theequation}{\AppLet.\arabic{equation}}
\renewcommand{\thefigure}{\AppLet.\arabic{figure}}

\renewcommand{\rmdefault}{phv}   % Arial
\renewcommand{\sfdefault}{phv}   % Arial


\newcommand\ymrfig[2]{    % filename is #1, text is #2
  \begin{figure}[htp]
  \begin{center}
  \epsfxsize=6in
  \epsfbox{#1.eps}
  \end{center}
  \caption{#2 }
  \label{fig:#1} 
  \end{figure}
  % \clearpage  
}

\newcommand\twofig[3]{    % figure #1 under #2, caption text #3
  \begin{figure}[htp]            %  label will be #1
  \centering
  \begin{tabular}{c}
  \epsfbox{#1.eps} \\
  \epsfbox{#2.eps}
  \end{tabular}
  \caption{#3}
  \label{fig:#1}
  \end{figure}
}

\SweaveOpts{pdf=FALSE}        % keep.source=TRUE, 
% Most useful options (with defaults):
% echo = TRUE  - includes R code in output file
% keep.source = FALSE - when echoing, if TRUE then original source is
%  copied to the file, otherwise deparsed source is echoed.
% eval = TRUE - if FALSE then chunk is not evaluated
% results = VERBATIM - R output included verbatim, if TEX output is 
%  already proper latex and included as is, if HIDE then all output
%  is completely suppressed (but the code executed - good for admb)
% pdf = TRUE - whether .pdf figures shall be generated
% eps = TRUE - whether .eps figures shall be generated
% strip.white = FALSE - if true then blank lines at beginning and
%  end of output are removed. If all, then all blank lines are removed.
% width = 6  - width of figures in inches
% height = 6 - height of figures in inches
% fig = FALSE - whether the code chunk produces graphical output 
%  (only one per chunk)
% \setkeys{Gin}{width=6in}     % from googling sweave figure bigger.
%  It will set this for the rest of document 
%  [doesn't width do that in the above?]

\begin{document}
\setcounter{page}{\StartP}

\begin{center}

{\Large \bf Yellowmouth MCMC working results}

\vspace{7mm}

{\Large \bf Andrew M.~Edwards, Rowan Haigh and Paul J.~Starr}

% This file started 5th April 2011.

Latest is \today, with \Sexpr{print(version$version.string)}. 
% \Sexpr{print(version$platform)}.

% {\tt Andrew.Edwards@dfo-mpo.gc.ca}

% \vspace{4mm}

\end{center}

% First set up workspace:
<<setupworkspace, echo=FALSE, results=hide>>= # hide the results 
# '@variables' replaced by runSweave.
cwd = "@cwd"            # Top level directory; all models occur below this one. 
#rm(list=ls())  
# require(PBSfishery)   # also loads mapping, modelling, data, RODBC
# require(PBSadmb)      # 1st run of these will show package numbers etc.
#require(PBSmodelling)
#require(xtable) 
#require(lattice)
# readADopts()
# Arni Magnusson's support functions for Awatea.
#library(scape)
# Arni Magnusson's support functions for Awatea MCMC.
#library(scapeMCMC)
# Data manipulation functions from CRAN.
#library(gdata)

# Function Definitions 
#source("../../ymrScape.r")
@ 

% '@variables' replaced by function 'runSweave' to create individual Sweaves for runs and reweightings.
<<modelname, echo=FALSE>>=
model.name     = "@model.name"
run.dir        = "@run.dir"
fig.dir        = "@fig.dir"
msy.dir        = "@msy.dir"
prj.dir        = "@prj.dir"
running.awatea = @running.awatea   # 0 if just loading previous '.rep'; 1 if rerunning Awatea
@ 
<<awatea.run, results=HIDE, echo = FALSE>>=
if(running.awatea) {
  # makeAD(model.name)
  # runAD(model.name)
  # need to go up a directory, as running Awatea there and doing 
  #  figures here
  #wd = getwd()
  #setwd("..")
  setwd(run.dir)
  shell( paste("awatea -ind ", model.name,".txt -nohess", sep=""))
  #  HAVE to do hess for MCMC
  # shell(     - copy results.dat to results model.name .dat)
  setwd(cwd)     # back to current directory
  } 
@ 

\pagestyle{myheadings}
\markright{\Sexpr{paste("From MCMC", model.name, sep="")}}

Plotting MCMC output for model {\tt \Sexpr{model.name}}. 
% Loading in *****{\tt \Sexpr{model.name}.***} file, that has already been created.

% We {\bf are}~{\bf \Sexpr{if(!running.awatea) paste("NOT")}} re-running Awatea here\Sexpr{if(!running.awatea) paste(" so just loading in outputNOT")}.

% If editing {\tt .txt} file, may have to rerun just in dos/R first to check the output from ADMB (otherwise errors get hidden): 

% {\tt > shell( paste("awatea -ind ../", model.name,".txt -nohess", sep=""))}

\section{History of Runs}


{\tt Run01}: 1 survey (WCVI Syn + US Triennial stitched just to get something running), no CPUE series, estimating $R_0$ and $q$ only, initial run with many POP QCS defaults. \newline  

\noindent {\tt Run02}: Same as {\tt Run01}, but estimating all parameters. Tried extra reweightings to see if they made a difference (because average weights looked a worse fit for first reweighting than no reweighting). For ageing data, first reweight downweights survey effective sample size (originally 10, 8, 8, 29), first reweight is 15\% of that (so fit is worse). Commercial increases to 1.73 times, so it somewhat prefers that data. \newline

\noindent {\tt Run03}: From Paul (his {\tt InputPOP wcvi 05A.txt}), 25/7/12. Now starts from 1976, many (but not all) of the parameters estimated. Gives moderately sensible results. Contains the 17 CPUE indices and the 1996 Caledonian survey estimate. Now estimating {\tt log init devs}: deviates for initial age structure; {\tt initial R}: number 1-year olds in year 1 relative to $R_0$ (**perhaps); {\tt initial u}: exploitation for initial age structure (one for each sex); {\tt plus scale}: multiplier on the "plus" group, which recognises that the cumulative exploitation on the plus group will exceed the estimate made by the parameter 'initial u' (one parameter for each sex). Find $R_0 \simeq 1700$, {\tt uinit}$\simeq 0.01$ and the plus-scale is a very small number. I don't think these make sense.  It may be a better idea to not estimate plus-scale at this point.  And {\tt Rinit}$>1$, which also seems silly. It's still early days, but it looks like this approach will lead to an assessment, which is good news. \newline

\noindent {\tt Run04}: Same as {\tt Run03}, but setting priors for natural mortality to Normal(0.067, sd$=$0.0029) for females, Normal(0.073, 0.0031) for males, based on posteriors of QCS POP assessment. May want to (i) use one prior for both sexes (Normal(0.07, 0.003)), or (ii) make priors broader. Take out 1996 synoptic survey index that was included (it was targetting POP and caught POP about twice as frequently as the later cruises - see Paul's Appendix C). Also using priors for selectivity parameters based on posteriors from QCS (see {\tt POP12SelPrior.pdf}), which works out normal distribution priors. I noticed in the previous input file these were set as uniforms, but I've changed to normals which seems to work. \newline

\noindent {\tt Run05}: Same as {\tt Run04} with changes: (1) log init devs changed from phase 3 to phase 2. (2) Tried changing 'Survey catch at age likelihood type' survey1 to '0' (from 12), with dummy set of catch-at-age data for survey1 (this gives the same par and MPD estimates but throws the indexing off for catch-at-age fits; therefore reverted to one catch-at-age series with no dummy). (3) Updated the WCVI synoptic survey biomass estimates to reflect some minor changes in all of them, except for 2010 survey which has changed a lot. \newline

\noindent {\tt Run06}: Upon the advice of the POP working group (meeting 2012-08-01) the age composition was shortened to 30 age bins, where 30 acts as a plus class. Also in this run, a third survey series (GB Reed: 1967-70) was added. Note that Awatea currently has an indexing bug in the output routine regarding survey (and possibly commercial) catch-at-age fits. Therefore, the last survey (WCVI Synoptic) is labelled the first (and survey 2 = NMFS Triennial, survey 3 = GB Reed). \newline

\noindent {\tt Run07}: Same as {\tt Run06} except for placing priors on natural mortality and selectivity. M is fixed to the mean of the prior. \newline

\noindent {\tt Run08}: Same as {\tt Run07} except M is estimated. \newline

\medskip

\noindent Using Run29 and Run30 as 'Estimate $M$' and 'Fix $M$' main runs in YMR write-up, with Run24 and Run28 mentioned in as sensitivites to including simple ageing error.

% GOT TO HERE ending for Sweave
% \end{document}
% <<stopping>>=
% stop("GOT TO HERE")
% @ 


<<fromscape, results=HIDE, echo=FALSE>>=
# Commenting some out for ymr.
#--------------------------------------------------------------------#   AME Commands that are actually run.

# Set style of reconstruction-projection plots.
# Options: "lines", "lineDot", "quantBox"
rpType <- "quantBox"

trellis.device(device="postscript", color=TRUE)   # for colour .eps

# Load in .res file.
setwd(fig.dir) 
#currentRes <- importCol2(paste("../", model.name, ".res", sep=""), 
currentRes = importRes(paste(run.dir,"/", model.name, ".res", sep=""), 
             Dev=TRUE, CPUE=TRUE, Survey=TRUE, 
             CLc=TRUE, CLs=TRUE, CAs=TRUE, CAc=TRUE, extra=TRUE)

sigmaR = currentRes$extra$residuals$p_log_RecDev[6]
    # to use when importing projected recruitment deviations (that
    #  are actually just the random N(0,1) numbers so need 
    #  multiplying by sigmaR).

# Assign a generic title for use in some plots.
mainTitle <- "@sppname"

# Minimum data year for tuning index.
minCpueYr <- 1940
#ACH: I'm not sure exactly what this is for but I set it to the start year

# Set the policy list for projection plots here.
#policy <- c( "0","400","800","1200","1600","2000" )
# Don't think I used for POP
# policy <- c( "0","100","200","300","400","500","600","700",
#              "800","900","1000","1100","1200" )

# Set the reference years and functions for performance measures.
# <deleted - see popScape2.r>

# AME loading in automatically the MCMC and projection file, to
#  save having to do the menus (good for debugging, but presumably
#  will give error if file not there, so need to remove for non-MCMC)

# Awatea MCMC.
currentMCMC <- importMCMC( dir=".", quiet=FALSE )
assign( "currentMCMC", currentMCMC, pos=1 )


currentMCMCorig = currentMCMC  
       # to use below
# importMCMC (a scape function) seems to get years wrong on the recruitment, see popScape2.r for details, here is the fix
names(currentMCMC$R) = as.integer(names(currentMCMC$R)) + 1
                                        #currentRes$B$R seems one off
# Also change names of estimated parameters to those matching my
#  write up, and change to the same order. See POPscape2.r .
# To see defauls given by Awatea do:
#  names(currentMCMCorig$P)
# Will have to do a switch for CPUE. ***** and add extra surveys,
#  Extra surveys not done automatically.

# **** AME hard-wiring cannot work; RH attempt to fix: ***
#==========================================================
# Get the commercial and survey index series
Cser=unique(currentRes$CPUE$Series);   NCser=length(Cser)
Sser=unique(currentRes$Survey$Series); NSser=length(Sser)

# Get the commercial and survey age series
CAser=unique(currentRes$CAc$Series);   NCAser=length(CAser)
SAser=unique(currentRes$CAs$Series);   NSAser=length(SAser)

Ncomm = max(NCser,NCAser)
Nsurv = max(NSser,NSAser)

Pnames = names(currentMCMC$P)
new.Pnames = gsub("M2",paste("M_",2,sep=""),sub("M1",paste("M_",1,sep=""),sub("R0","R_0",Pnames)))
for (i in 1:Ncomm) {
	ii = i + Nsurv
	new.Pnames = sub(paste("Sfullest_",i,sep=""),paste("mu_",ii,sep=""),new.Pnames)
	new.Pnames = sub(paste("log_varLest_",i,sep=""),paste("log v_",ii,"L",sep=""),new.Pnames)
	new.Pnames = sub(paste("Sfulldelta_",i,sep=""),paste("Delta_",ii,sep=""),new.Pnames)
	new.Pnames = sub(paste("log_qCPUE_",i,sep=""),paste("log q_",ii,sep=""),new.Pnames)
}
for (i in 1:Nsurv) {
	ii = Sser[i]
	new.Pnames = sub(paste("surveySfull_",i,sep=""),paste("mu_",ii,sep=""),new.Pnames)
	new.Pnames = sub(paste("log_surveyvarL_",i,sep=""),paste("log v_",ii,"L",sep=""),new.Pnames)
	new.Pnames = sub(paste("surveySfulldeltaest_",i,sep=""),paste("Delta_",ii,sep=""),new.Pnames)
	new.Pnames = sub(paste("log_qsurvey_",i,sep=""),paste("log q_",ii,sep=""),new.Pnames)
}
new.Pnames = sub("log_BetaCPUE","log beta",new.Pnames)
tab.Pnames = c("R_0","M_1","M_2","h",paste("log q_",1:(Nsurv+Ncomm),sep=""),"log beta",
	paste("mu_",1:(Nsurv+Ncomm),sep=""),paste("Delta_",1:(Nsurv+Ncomm),sep=""),paste("log v_",1:(Nsurv+Ncomm),"L",sep=""))
use.Pnames = tab.Pnames[is.element(tab.Pnames,new.Pnames)]

# Assign new names
names(currentMCMC$P) = new.Pnames
# Re-order to match Paul's results table 3:
currentMCMC$P = currentMCMC$P[,use.Pnames]

# Now going to use q_1, q_2, q_3, not log q_1 etc.
qnames = use.Pnames[grep("log q_",use.Pnames)]
for (i in qnames) {
	currentMCMC$P[,i] = exp(currentMCMC$P[,i])
}
names(currentMCMC$P)[is.element(names(currentMCMC$P),qnames)] = substring(qnames,5)
# End RH fix
#==========================================================

# Need this here to use as a switch for CPUE being estimated or not:
#logbetaCPUE.prior = currentRes$extra$priors$log_BetaCPUE
#if(logbetaCPUE.prior[1] > 0)       # Then estimating CPUE parameters
#  {
#    new.Pnames = c("R_0", "h", "M_1", "M_2", "mu_6", "Delta_6", "log v_6L", "log q_6", "log beta", "log q_1", "log q_2", "log q_3", "log q_4", "log q_5", "mu_1", "mu_2", "Delta_1", "Delta_2", "log v_1L", "log v_2L")
#  names(currentMCMC$P) = new.Pnames
#  # re-order to match Paul's results table 3:
#  currentMCMC$P = currentMCMC$P[, c( "R_0",  "M_1", "M_2", "h",
# "log q_1", "log q_2", "log q_3", "log q_4", "log q_5",
# "log q_6", "log beta",
# "mu_1", "mu_2", "mu_6",
# "Delta_1", "Delta_2", "Delta_6",
# "log v_1L", "log v_2L", "log v_6L")]
#  # not going to use log for q's or beta  
#  currentMCMC$P[,"log q_6"] = exp(currentMCMC$P[,"log q_6"])
#  names(currentMCMC$P)[names(currentMCMC$P) == "log q_6"] = "q_6"
#  }  else        # no beta or q_6
#  {                                
#    new.Pnames = c("R_0", "h", "M_1", "M_2", "mu_6", "Delta_6", "log v_6L", "log q_1", "log q_2", "log q_3", "log q_4", "log q_5", "mu_1", "mu_2", "Delta_1", "Delta_2", "log v_1L", "log v_2L")
#    names(currentMCMC$P) = new.Pnames
#    # re-order to match Paul's results table 3:
#    currentMCMC$P = currentMCMC$P[, c( "R_0",  "M_1", "M_2", "h",
# "log q_1", "log q_2", "log q_3", "log q_4", "log q_5",
# "mu_1", "mu_2", "mu_6",
# "Delta_1", "Delta_2", "Delta_6",
# "log v_1L", "log v_2L", "log v_6L")]
#  }

# Now going to use q_1, q_2, q_3, not log q_1 etc.
#currentMCMC$P[,"log q_1"] = exp(currentMCMC$P[,"log q_1"])
#currentMCMC$P[,"log q_2"] = exp(currentMCMC$P[,"log q_2"])
#currentMCMC$P[,"log q_3"] = exp(currentMCMC$P[,"log q_3"])
#currentMCMC$P[,"log q_4"] = exp(currentMCMC$P[,"log q_4"])
#currentMCMC$P[,"log q_5"] = exp(currentMCMC$P[,"log q_5"])

#names(currentMCMC$P)[names(currentMCMC$P) == "log q_1"] = "q_1"
#names(currentMCMC$P)[names(currentMCMC$P) == "log q_2"] = "q_2"
#names(currentMCMC$P)[names(currentMCMC$P) == "log q_3"] = "q_3"
#names(currentMCMC$P)[names(currentMCMC$P) == "log q_4"] = "q_4"
#names(currentMCMC$P)[names(currentMCMC$P) == "log q_5"] = "q_5"

# Also have to import vulnerable biomass from vulnBiom.pst, as it's
#  not done in importMCMC. Can just do as a data table. Has columns
#  representing years, and each of 1000 rows is an MCMC sample. Same
#  size as currentMCMC$B. It is
#  calculated as denominator of (D.11) in POP model appendix.

vbMCMC = read.table("vulnBiom.pst", header=TRUE)
names(vbMCMC) = names(currentMCMC$B)      # to make them simply years
currentMCMC[["VB"]] = vbMCMC
       # Add to currentMCMC so that it gets called into functions.

# Awatea projection.
# The importProj function loads a list with elements "B" and "Y" for 
# biomass by catch policy and year, and catch by harvest policy and 
# year.  The "B" element is itself a list of matrices with a matrix 
# for each level of the catch.  This matrix has rows equal to the   
# length of the chain and columns corresponding to projection years.
# There are no [specific - AME] plotting routines for these data.    

# currentProj$eps is a list of data frames, one for each catch
#  strategy, though each data frame is the same (because the same
#  random N(0,1) are used for each one). Each data frame is 1000x91
#  as each row is an MCMC sample and each column is projected year,
#  from 2011 to 2101. For a given MCMC sample, the same random
#  numbers are used for each strategy (but random numbers are
#  different between MCMC samples). i.e.:
# > range(currentProj$eps$'0'[1,] - currentProj$eps$'0'[2,] )
# [1] -2.722770  2.844936
# > range(currentProj$eps$'0'[1,] - currentProj$eps$'250'[1,] )
# [1] 0 0
# So although the eps are the same for each strategy, the actual
#  recruitments won't be because the spawning biomassess will be
#  changing (first year should be the same though).

# currentProj <- importProj( dir=".", quiet=FALSE )

currentProj <- importProjRec( dir=prj.dir, quiet=FALSE )
   # importProjRec includes epsilons for recruitments
   # Then below we calcualte the actual recruitments.

assign( "currentProj", currentProj, pos=1 )
# Take off final year of projection
currentProj$B = lapply(currentProj$B, function(x) {  x[ ,1:(dim(x)[[2]]-1)]  })
currentProj$Y = lapply(currentProj$Y, function(x) { x[ ,1:(dim(x)[[2]]-1)]  })
currentProj$eps = lapply(currentProj$eps, function(x) {  x[ ,1:(dim(x)[[2]]-1)] })
# currentProj$R is calculated below
# sd(unlist(currentProj$eps$'0'))
# [1] 0.8993165
#  sd(unlist(currentProjaa$eps$'250'))
# [1] 0.8993165
#  etc., as they're all the same, and the sd equals sigmaR.


# Awatea MSY.
currentMSY <- msyCalc( dir=msy.dir, error.rep = 0 )
assign( "currentMSY", currentMSY, pos=1 )      # Forces it global (or something)

# Do these for ease of showing statistics in tables. Each should be a vector with value 
#  for each MCMC draw
B0.MCMC = currentMCMC$B[,1]
# To calculate trajectory for Bt/B0 MCMC's, do:
# BoverB0 = currentMCMC$B / B0.MCMC     # B/B0  each chain
# BoverB0med = apply(BoverB0, 2, median)         # median each year

Year = rev(dimnames(currentMCMC$B)[[2]])[1]      # character starting year
Year0 = as.numeric(Year)                         # numeric starting year
#Ypro  = dimnames(currentProj$B[[1]])[[2]]        # character available projection years
#Ypr0  = as.numeric(Ypro)                         # numeric available projection years

Bcurr.MCMC = currentMCMC$B[,Year]
VB0.MCMC = currentMCMC$VB[,1]
VBcurr.MCMC = currentMCMC$VB[,Year]
Bmsy.MCMC = currentMSY$B
VBmsy.MCMC = currentMSY$VB
msy.MCMC = currentMSY$yield
umsy.MCMC = currentMSY$u


# To calculate the actual projected recruitments (from the eps)
currentProj$R = list()
NN = matrix(1:1000, nrow=1)      # to use to populate each data.frame
projYearsNames = names(currentProj$B[[1]])
projYearsNum   = length(projYearsNames)

# First calculate recruits for first projection year, which is based
#  on penultimate MCMC year's spawners (which is 2010, final year
#  of that is 2011, first proj year is 2011, and I checked that
#  values for last year of MCMC equal those for first yr of proj:
#  > range(currentMCMC$B[, 72] - currentProj$B$'250'[, 1])
#      0 0.
# Do this here as does not depend on projections (and so is same for
#  all catch strategies).
Bpen.MCMC = currentMCMC$B[, rev(names(currentMCMC$B))[2]]
     # spawning biomass for penultimate year of MCMC

if (!is.element("h",use.Pnames))
	currentMCMC$P$h = rep(currentRes$extra$parameters$h, dim(currentMCMC$P)[[1]])
RfirstProj = srFun(Bpen.MCMC, R0 = currentMCMC$P$R_0, h=currentMCMC$P$h, B0=B0.MCMC)

# Stochastic multiplier, will be same for all strategies as random
#  numbers currentProj$eps[[j]] are the same for each strategy j
stochMult = exp(currentProj$eps$'0' - sigmaR^2/2)

for(j in 1:length(currentProj$eps) )    # loop over policies
  {
  junk = apply(NN, 2, function(i, B, R0, h, B0) {
   srFun(as.numeric(B[i,]), h = h[i], R0=R0[i], B0=B0[i] ) },
   B = currentProj$B[[j]],
   R0 = currentMCMC$P$R_0, h = currentMCMC$P$h, B0=B0.MCMC)
       # Rowan's trick for using apply on each row.
  junk = t(junk)
  junk = as.data.frame(junk)
       # This gives data
       #  frame, rows are MCMC samples, columns are recruits for the
       #  next year. Need to insert RfirstProj as first column,
       #  and remove final column (which
       #  corresponds to recruits for the year after final projection
       #  year).
  detR = cbind(RfirstProj, junk)
  detR = detR[, -dim(detR)[2] ]     # take off final column
  names(detR) = projYearsNames      # detR is deterministic values
  stochR = detR * stochMult
  currentProj$R[[j]] = stochR
  }
names(currentProj$R) = names(currentProj$eps)


# Bmsy Reference points (could move this to scape at some point):

refPointsList = refPoints()  # ONLY set up for default 0.4, 0.8 
                    #  and 1 Bmsy at the moment *****
refProbsList = calc.refProbs() # currentMCMC$B, currentProj$B, refPointsList)
# That's a list, each element is the full table for P> LRP, URP or Bmsy, rows are 
#  const catch scenarios and columns are years.
# Full ymr calc is: 
# row.names(temp$LRP)
# [1] "0"    "250"  "500"  "750"  "1000" "1250" "1500" "1750" "2000" "2250"
# [11] "2500" "2750" "3000"
# row.names(t(temp$LRP))    # col.names didn't work?!
#  "2011" "2012" .... "2032"

# scenarioSubset = c("0", "500", "1000", "1500", "2000" "2250"....
fiveYears   = as.character(Year0+seq(0,5,1))
twentyYears = as.character(Year0+seq(0,20,5))
ninetyYears = as.character(Year0+seq(0,90,15))

refProbs5 = list()    # Probs for 5 years
refProbs20 = list()   # Probs for 20 years
refProbs90 = list()   # Probs for 90 years
for(i in 1:length(refProbsList))
	{
	if (projYearsNum>=5) {
		refProbs5[[i]] = refProbsList[[i]][,fiveYears]
		names(refProbs5)[i] = names(refProbsList)[i] }
	if (projYearsNum>=20) {
		refProbs20[[i]] = refProbsList[[i]][,twentyYears]
		names(refProbs20)[i] = names(refProbsList)[i] }
	if (projYearsNum>=90) {
		refProbs90[[i]] = refProbsList[[i]][,ninetyYears]
		colnames(refProbs90[[i]]) =  as.numeric(colnames(refProbs90[[i]])) - Year0
		names(refProbs90)[i] = names(refProbsList)[i] }
	}

# B0 Reference points, not doing moving window here yet 
#  (could move this to scape at some point):

B0refLevels=c(0.2, 0.4, 0.5, 0.7)
B0refNames = paste("B0", B0refLevels, sep="")
refPointsB0List = refPointsB0()     # Above two lines are defaults

refProbsB0List = calc.refProbs(refPlist = refPointsB0List)
# That's a list, each element is the full table for P> each ref point,
#  rows are const catch scenarios and columns are years.
# Check, should get:
# row.names(temp$B00.2)
# [1] "0"    "250"  "500"....
# row.names(t(temp$B00.2))      colnames(...) works
#  "2011" "2012" .... "2101"

# scenarioSubset = c("0", "500", "1000", "1500", "2000" "2250"....

refProbsB05 = list()    # Probs for 5 years
refProbsB020 = list()   # Probs for 20 years
refProbsB090 = list()   # Probs for 90 years
for(i in 1:length(refProbsB0List))
	{
	if (projYearsNum>=5) {
		refProbsB05[[i]] = refProbsB0List[[i]][,fiveYears]
		names(refProbsB05)[i] = names(refProbsB0List)[i] }
	if (projYearsNum>=20) {
		refProbsB020[[i]] = refProbsB0List[[i]][,twentyYears]
		names(refProbsB020)[i] = names(refProbsB0List)[i] }
	if (projYearsNum>=90) {
		refProbsB090[[i]] = refProbsB0List[[i]][,ninetyYears]
		colnames(refProbsB090[[i]]) =  as.numeric(colnames(refProbsB090[[i]])) - Year0
		names(refProbsB090)[i] = names(refProbsB0List)[i] }
	}
# To give 0, 15 ... as colnames for decision tables
 

# Moving window reference points from Rowan's findTarget.r code,
#  which also calculates 0.4 Bmsy and others.

refProbs3GenList = list()        # Probabilities for decision tables
               #  Will include 0.4Bmsy etc. already calculated above
               #  e.g., refProbs3Gen5$'0.4Bmsy' - refProbs5$LRP  = 0
#list of targets:
Tlst = list(list(ratio=0.4,target=Bmsy.MCMC),
  list(ratio=0.8,target=Bmsy.MCMC),
  list(ratio=0.2,target=B0.MCMC),
  list(ratio=0.4,target=B0.MCMC),
  list(ratio=0.5,target=currentMCMC$B),
  list(ratio=0.7,target=currentMCMC$B))
names(Tlst)=c("0.4Bmsy","0.8Bmsy","0.2B0","0.4B0","0.5Gen3","0.7Gen3")

refProbs3GenList = sapply(Tlst,function(x){sapply(currentProj$B,
  findTarget,ratio=x$ratio,target=x$target,retVal="p.hi")},
  simplify=FALSE)
refProbs3GenList = sapply(refProbs3GenList,t,simplify=FALSE) 
                                        # transpose matrices
refProbs3Gen5 = list()    # Probs for 5 years
refProbs3Gen90 = list()   # Probs for 90 years

for(i in 1:length(refProbs3GenList))
	{
	if (projYearsNum>=5) {
		refProbs3Gen5[[i]] = refProbs3GenList[[i]][,fiveYears]
		names(refProbs3Gen5)[i] = names(refProbs3GenList)[i] }
	if (projYearsNum>=90) {
		refProbs3Gen90[[i]] = refProbs3GenList[[i]][,ninetyYears]
		colnames(refProbs3Gen90[[i]]) =  as.numeric(colnames(refProbs3Gen90[[i]])) - Year0
		names(refProbs3Gen90)[i] = names(refProbs3GenList)[i] }
	}
# To give 0, 15 ... as colnames for decision tables

# Also calculate number of years to reach reference target points
#  with a specified confidence, 0.5, 0.8 and 0.95
Ttab0.5 = sapply(Tlst,function(x){sapply(currentProj$B,findTarget,ratio=x$ratio,target=x$target,conf=0.5,retVal="N")})
Ttab0.8 = sapply(Tlst,function(x){sapply(currentProj$B,findTarget,ratio=x$ratio,target=x$target,conf=0.8,retVal="N")})
Ttab0.95 = sapply(Tlst,function(x){sapply(currentProj$B,findTarget,ratio=x$ratio,target=x$target,conf=0.95,retVal="N")})

# Need to calculate exploitation rates over time for MCMC (MPD's are
#  included in currentRes, but nothing in currentMCMC. Going to add
#  currentMCMC$U to currentMCMC. After doing this realised it was
#  sort of done in popScapeRuns2.r, but only internally for plotting
#  figures.

catch = currentRes$B$Y[-length(currentRes$B$Y)]   # take off 2011 NA

currentMCMC$U = currentMCMC$VB[,-dim(currentMCMC$VB)[2]] # Don't want                                        # 2011, as no catch
names.cmu = names(currentMCMC$U)
currentMCMC$U = t(apply(currentMCMC$U, 1, function(x,y){ y/x }, y=catch))    # Need transpose to get right way round again
names(currentMCMC$U) = names.cmu 
# So currentMCMC$U is now exploitation rate for MCMC output.
ucurr.MCMC = currentMCMC$U[,as.character(Year0-1)]
umax.MCMC = apply(currentMCMC$U, 1, max)

# u.MCMC.med = apply(currentMCMC$U, 2, median)  # median for each year
# For snail plots:
currentMCMC$UoverUmsy = apply(currentMCMC$U, 2, function(x,y){ x/y },  y=umsy.MCMC)    # No transpose
UoverUmsy.med = apply(currentMCMC$UoverUmsy, 2, median)
#  qtab(currentMCMC$UoverUmsy[,"2010"], dig=3 )    agrees with values
#   below in the table

currentMCMC$BoverBmsy = apply(currentMCMC$B, 2, function(x,y){ x/y },  y=Bmsy.MCMC)    # No transpose, also agrees with table below
BoverBmsy.med = apply(currentMCMC$BoverBmsy, 2, median)

# Did this to check MPD's closely matched the medians, they more or 
#  less do:
# plot(apply(currentMCMC$U, 2, median))
# points(currentRes$B$U, col="red")

# For SARA need to calculate Z = M+F = M-log(1-u), so have to do for
#  females and males. Work it out for each MCMC draw, then get the 
#  quantiles from the resulting 1000 values. But if M fixed then
#  just have u to worry about.

# Estimate M:
# Z1 = currentMCMC$P[,"M_1"] - log(1 - u2010.MCMC)
# quantile(Z1, p=c(0.05, 0.50, 0.95))
# Z2 = currentMCMC$P[,"M_2"] - log(1 - u2010.MCMC)
# quantile(Z2, p=c(0.05, 0.50, 0.95))

# Fix M, for females (males the same if fixed values the same):
# Z1 = M1.prior[7] - log(1 - u2010.MCMC)
# quantile(Z1, p=c(0.05, 0.50, 0.95))

quantiles = c(0.05, 0.5, 0.95)      # for tables
# Next was for saving to an .RData file to load into 
#  ../../../POPdeterminR/POPdeterminR.r   to run deterministic model.
# First give variable names that match my write up, then save them 
#  all.
# First set are to be used as input, second set as confirmation.
# For YMR, for now commenting out ones from MCMC.

A = max(currentRes$Sel[,"Age"])
T = diff(range(currentRes$B[,"Year"]))+1       # =72
Ct = currentRes$B$Y[-length(currentRes$B$Y)]    # Takes off 2011 value
years = currentRes$B[,"Year"]
ages = sort(unique(currentRes$CAc$Age))

selgeqComm = currentRes$Sel[currentRes$Sel$"Series" == "Gear 1",] 
    # comm sel, selgeq4 for POP, presumably woudl be 6 for YMR as
    #  5 surveyrs, so just write Comm
mat = currentRes$Sel[currentRes$Sel$"Series" == "Maturity" &
       currentRes$Sel$"Sex" == "Female",]      # Female maturity
# M1 = currentMCMC$P[1,"M_1"]           # MPD is first line of MCMC
# M2 = currentMCMC$P[1,"M_2"]           # MPD is first line of MCMC
Rt = currentRes$B$R[-length(currentRes$B$R)]   
                                        # Remove final NA for 2011,
Rt.mpd = Rt       # don't think Rt gets used elsewhere, but leave
                  #  it valid just in case.
# For confirmation:
# R0.mpd = currentMCMC$P[1,"R_0"] #Matches numbers from Ro_So_VB.pst,
                                  # but wasn't going to use that 
                                  #  before?
# h.mpd = currentMCMC$P[1,"h"]
Nats.mpd = currentRes$N
ut.mpd = currentRes$B$U[-length(currentRes$B$U)]  
                                  # remove final NA for 2011
Bt.mpd = currentRes$B$SB
B0.mpd = Bt.mpd[1]
Vt.mpd = currentRes$B$V
logRecDev.mpd = currentRes$Dev$Annual
# Also equals currentRes$extra$parameters$log_RecDev from Rowan's 'extra' sublist  in currentRes.
# From Rowan's extra function, to give the mpd's:
R0.mpd = currentRes$extra$parameters$R0
M1.mpd = currentRes$extra$parameters$M1[1]
M2.mpd = currentRes$extra$parameters$M1[2]
h.mpd = currentRes$extra$parameters$h
qvec.mpd = exp(currentRes$extra$parameters$log_qsurvey) # surveys

# CPUE:
qCPUE.mpd = exp(currentRes$extra$parameters$log_qCPUE)  # q for CPUE
betaCPUE.mpd = exp(currentRes$extra$parameters$log_BetaCPUE)

# survey selectivities:
muvec.mpd = currentRes$extra$parameters$surveySfull    
deltavec.mpd = currentRes$extra$parameters$survey_SfullDelta 
logvvec.mpd = currentRes$extra$parameters$log_surveyvarL

# commercial selectivities:
mu6.mpd = currentRes$extra$parameters$Sfullest    # comm mu
delta6.mpd = currentRes$extra$parameters$SfullDelta
logv6.mpd = currentRes$extra$parameters$log_varLest

# From Rowan's extra function, to give the priors, not all are _prior
R0.prior = currentRes$extra$priors$R0_prior
M1.prior = currentRes$extra$priors$M1_prior[1,] 
M2.prior = currentRes$extra$priors$M1_prior[2,]
h.prior = currentRes$extra$priors$h_prior
logqvec.prior = currentRes$extra$priors$log_qsurvey_prior# surveys, matrix

# CPUE:
logqCPUE.prior = currentRes$extra$priors$log_qCPUE  # q for CPUE
#    moved next one to above to use as switch when changing names
#    of MCMC posteriors.
# logbetaCPUE.prior = currentRes$extra$priors$log_BetaCPUE

# survey selectivities (all matrices):
muvec.prior = currentRes$extra$priors$surveySfull_prior
deltavec.prior = currentRes$extra$priors$p_surveySfulldelta 
logvvec.prior = currentRes$extra$priors$log_surveyvarL_prior

# commercial selectivities:
mu6.prior = currentRes$extra$priors$p_Sfullest    # comm mu
delta6.prior = currentRes$extra$priors$p_Sfulldelta
logv6.prior = currentRes$extra$priors$log_varLest_prior

##### Debugged to here (RH) #####


# To make a list of priors to use in plotDensPOPParsPrior().
#  For ymr for now not automating, as short on time.
# Might need this to do automatically:
# sapply(currentRes$extra$priors, function(x) {if(is.array(x)) return(x[,1]) else return(x[1])})

# DID THIS IN plotDensPOPparsPrior.r to get working, then copy here:
priorDistList = list()     # Need a list to be functions to go into
priorBoundsList = list()      # panel.curve
                           # And need bounds for panel.curve, which
                           #  are a bit fiddly from Rowan's
                           #  currentRes$extra$priors  as order is
                           #  different and q's are grouped, so
                           #  panel.number() can't be used. Should
                           #  tidy all this up afterwards.
  i = 1    # i to increment so get List of correct length to use
         #  panel.number() in panel.curve

  priorDistList[[i]] = function(x) 
      { dunif(x, min = R0.prior[2], max = R0.prior[3])
      }
  priorBoundsList[[i]] = c( R0.prior[2], R0.prior[3])
  i = i+1

  if(length(currentMCMC$P$M_1) > 0)    # Then estimating M:
    {
      priorDistList[[i]] = function(x) 
        { dnorm(x, mean=M1.prior[5], sd=M1.prior[6])
        }
      priorBoundsList[[i]] = c( M1.prior[2], M1.prior[3])
      i = i+1
    
      priorDistList[[i]] = function(x) 
        { dnorm(x, mean=M2.prior[5], sd=M2.prior[6])
        }
      priorBoundsList[[i]] = c( M2.prior[2], M2.prior[3])
      i = i+1
    }

    # For h, pars in Awatea input are 4.574, 2.212, checking these
    #  are the shape1, shape2 parameters, which they are because
    #  these give the same prior for h as we had for POP:
    # mean(rbeta(100000, 4.574, 2.212))
    # [1] 0.674526
    # sd(rbeta(100000, 4.574, 2.212))
    # 0.1680018
	if(length(currentMCMC$P$h)>0 && unique(currentMCMC$P$h)>1) {   # Then estimating h: (RH note: temp. patch above = artificially populated h when h is fixed)
		priorDistList[[i]] = function(x) { dbeta(x, h.prior[5], h.prior[6]) }
		priorBoundsList[[i]] = c( h.prior[2], h.prior[3])
		i = i+1
	}
  # q1
  priorDistList[[i]] = function(q)
       { (q*( logqvec.prior[1,3] - logqvec.prior[1,2]))^(-1)
       }
        # log q uniform between a and b, then pdf for q is
        #  1/(q (b-a)) between exp(a) and exp(b)
        #  assuming don't need to plot outside of bounds. This
        #  didn't work as just returned single NA for a vector
        #  which is what panel.curve sends.
      #if(x > exp(logqvec.prior[1,2]) && x < exp(logqvec.prior[1,3]))
      #    {
      #      y = (x*( logqvec.prior[1,3] - logqvec.prior[1,2]))^(-1)
      #    } else
      #    { y = NA
      #    }
      #  return(y)  
  priorBoundsList[[i]] = c( exp(logqvec.prior[1,2]),
      exp(logqvec.prior[1,3]))   # Need to exp as not plotting on log
  i = i+1

    # q2     Have to increment the [[]], and the logqvec.prior[*,]
  priorDistList[[i]] = function(x)
       { (x*( logqvec.prior[2,3] - logqvec.prior[2,2]))^(-1)
       }
  priorBoundsList[[i]] = c( exp(logqvec.prior[2,2]),
      exp(logqvec.prior[2,3]))   # Need to exp as not plotting on log
  i = i+1

    # q3     Have to increment the [[]], and the logqvec.prior[*,]
  priorDistList[[i]] = function(x)
       { (x*( logqvec.prior[3,3] - logqvec.prior[3,2]))^(-1)
       }
  priorBoundsList[[i]] = c( exp(logqvec.prior[3,2]),
      exp(logqvec.prior[3,3]))   # Need to exp as not plotting on log
  i = i+1

    # q4     Have to increment the [[]], and the logqvec.prior[*,]
  priorDistList[[i]] = function(x)
       { (x*( logqvec.prior[4,3] - logqvec.prior[4,2]))^(-1)
       }
  priorBoundsList[[i]] = c( exp(logqvec.prior[4,2]),
      exp(logqvec.prior[4,3]))   # Need to exp as not plotting on log
  i = i+1

    # q5     Have to increment the [[]], and the logqvec.prior[*,]
  priorDistList[[i]] = function(x)
       { (x*( logqvec.prior[5,3] - logqvec.prior[5,2]))^(-1)
       }
  priorBoundsList[[i]] = c( exp(logqvec.prior[5,2]),
      exp(logqvec.prior[5,3]))   # Need to exp as not plotting on log
  i = i+1

    # mu1, row 1 of muvec.prior
  priorDistList[[i]] = function(x) 
      { dnorm(x, mean=muvec.prior[1,5], sd=muvec.prior[1,6])
      }
  priorBoundsList[[i]] = c( muvec.prior[1,2], muvec.prior[1,3])
i = i+1

    # mu2, row 2 of muvec.prior
  priorDistList[[i]] = function(x) 
      { dnorm(x, mean=muvec.prior[2,5], sd=muvec.prior[2,6])
      }
  priorBoundsList[[i]] = c( muvec.prior[2,2], muvec.prior[2,3])
  i = i+1

    # mu3, mu4, mu5 fixed.

    # mu6
  priorDistList[[i]] = function(x) 
      { dnorm(x, mean=mu6.prior[5], sd=mu6.prior[6])
      }
  priorBoundsList[[i]] = c( mu6.prior[2], mu6.prior[3])
  i = i+1

    # Delta1, row1 of deltavec.prior
  priorDistList[[i]] = function(x) 
      { dnorm(x, mean=deltavec.prior[1,5], sd=deltavec.prior[1,6])
      }
  priorBoundsList[[i]]= c(deltavec.prior[1,2],deltavec.prior[1,3])
  i = i+1

    # Delta2, row2 of deltavec.prior
  priorDistList[[i]] = function(x) 
      { dnorm(x, mean=deltavec.prior[2,5], sd=deltavec.prior[2,6])
      }
  priorBoundsList[[i]]= c(deltavec.prior[2,2],deltavec.prior[2,3])
  i = i+1

    # Delta6, delta6.prior
  priorDistList[[i]] = function(x) 
      { dnorm(x, mean=delta6.prior[5], sd=delta6.prior[6])
      }
  priorBoundsList[[i]]= c(delta6.prior[2],delta6.prior[3])
  i = i+1

    # log var1L, row1 of logvvec.prior
  priorDistList[[i]] = function(x) 
      { dnorm(x, mean=logvvec.prior[1,5], sd=logvvec.prior[1,6])
      }
  priorBoundsList[[i]]= c(logvvec.prior[1,2],logvvec.prior[1,3])
  i = i+1

    # log var2L, row2 of logvvec.prior
  priorDistList[[i]] = function(x) 
      { dnorm(x, mean=logvvec.prior[2,5], sd=logvvec.prior[2,6])
      }
  priorBoundsList[[i]]= c(logvvec.prior[2,2],logvvec.prior[2,3])
  i = i+1

    # log var6L, logv6.prior
  priorDistList[[i]] = function(x) 
      { dnorm(x, mean=logv6.prior[5], sd=logv6.prior[6])
      }
  priorBoundsList[[i]]= c(logv6.prior[2],logv6.prior[3])

# Moved from above, as now have currentMCMC$U calcs
# mainMenu() # don't want menu, just choose which:
# plt.mpdGraphs( currentRes, save=TRUE )
      #some now more correctly use MCMC results [don't think so now]
# plt.idx( currentRes$Survey,main="Survey Indices") # wasn't called 
#  in plt.mpdGraphs. Doing it here spits out SD of standardised 
#  residuals also. May be useful for iterative reweighting?
plt.mcmcGraphs( currentMCMC, currentProj, save=TRUE, 
               xlimrec=c(0,50000) ) 
              # xlimrec is x axis for recruitment posteriors, setting
              #  here for YMR.
close.allWin()


# function to use for priors in MPD table. Must read in a vector of 
#  length, and outputs it in the format for the table.
ptab = function(xx) 
  { print(paste(c(xx[1], " & [", xx[2], ",", xx[3], "] & ", 
          xx[4], " & [", xx[5], ",", xx[6], "] & ", xx[7]),
          sep="", collapse="")) 
  }
qtab = function(xx.MCMC, dig=0)     # dig is number of dec places
  { print(paste( c( round(quantile(xx.MCMC, 0.05), digits=dig), 
         " & ", round(quantile(xx.MCMC, 0.50), digits=dig), 
         " & ", round(quantile(xx.MCMC, 0.95), digits=dig)), 
         sep="", collapse=""))
  }  

# not saving for YMR for now (don't have all these variables, though
#  just MPDs so don't need MCMC output).  [These were from MCMC's]
# save(A, T, Ct, selgeqComm, mat, M1, M2, Rt, R0.mpd, h.mpd, Nats.mpd, ut.mpd,  Bt.mpd, B0.mpd, Vt.mpd, logRecDev.mpd, file="run23values.RData")
 # 
# save.image(file="run23all.RData")

# See popScape2.r for pairs plots, from:
# Copy and run this for pairs plots        to
# text(currentRes$B$SB, currentRes$B$U, 1:72)

# For fits:
#> windows(); plotBubbles(yy, dnam=TRUE, size=0.08, hide0=TRUE)
#>

# Also want to do catches and biomass predictions
# plot(years[-length(years)], Ct)
# > plot(years, Bt.mpd, ylim=c(0,200000))
# > plot(years, Bt.mpd, ylim=c(0,120000))
# > plot(years[-length(years)], Ct)

# Want to report the mean of the median recruitments for past and
#  projections.
recMed = apply(currentMCMC$R, 2, median)
meanRecMed = mean(recMed)
recProjMed1500 = apply(currentProj$R$'1500', 2, median)
meanRecProjMed1500 = mean(recProjMed1500)


@ 

% Comment out table parest for now (Priors and MPD estimates - see
%  ymrrun-master.Snw), though use that as template to make a table
% of posterior statistics

% Then find and replace run *** to Estimate M for the write up.

\ymrfig{traceParams}{MCMC traces for the primary estimated parametersfor run \Sexpr{model.name}. Grey lines show the 1000 samples for each parameter, solid lines show the cumulative median (up to that sample), and dashed lines show the cumulative 2.5 and 97.5 quantiles.  Red circles are the MPD estimates. Subscripts 1 to 5 are for surveys: GIG historical, QCS synoptic, QCS shrimp, WCHQ synoptic and WCVI synoptic. Subscript 6 is the commercial fishery.}   % for the base run "Estimate M \& h".

\ymrfig{splitChain}{Diagnostic plot for run \Sexpr{model.name}, obtained by dividing the MCMC chain of 1000 MCMC samples into three segments, and overplotting the cumulative distributions of the first segment (green), second segment (red) and final segment (blue).}
% overplotting the cumulative distributions, removing the first 100, then plotting the cumulative distributions for samples 101-400 (green), 301-700 (red) and 701-1000 (blue). }

\ymrfig{pairs1}{Pairs plot of 1000 MCMC samples for first six parameters for run \Sexpr{model.name}.}

\ymrfig{pairs2}{Pairs plot of 1000 MCMC samples for second six parameters for run \Sexpr{model.name}.}

\ymrfig{pairs3}{Pairs plot of 1000 MCMC samples for final parameters for run \Sexpr{model.name}.}



\ymrfig{traceBiomass}{MCMC traces for female spawning biomass estimates at five-year intervals for run \Sexpr{model.name}.  Note that vertical scales are different for each plot (to show convergence of the MCMC chain, rather than absolute differences in annual values). Grey lines show the 1000 samples for each parameter, solid lines show the cumulative  median (up to that sample), and dashed lines show the cumulative  2.5 and 97.5 quantiles.  Red circles are the MPD estimates.}

\ymrfig{traceRecruits}{MCMC traces for recruitment estimates at five-year intervals for run \Sexpr{model.name}. Note that vertical scales are different for each plot (to show convergence of the MCMC chain, rather than absolute differences in annual recruitment). Grey lines show the 1000 samples for each parameter, solid lines show the cumulative  median (up to that sample), and dashed lines show the cumulative  2.5 and 97.5 quantiles.  Red circles are the MPD estimates.}

\ymrfig{pdfParameters}{Marginal posterior densities (thick black curves) and prior density functions (thin blue curves) for the estimated parameters for run \Sexpr{model.name}. Vertical lines represent the 2.5, 50 and 97.5 percentiles, and red filled circles are the MPD estimates. For $R_0$ the prior is a uniform distribution on the range [\Sexpr{R0.prior[2]}, \Sexpr{R0.prior[3]}], and is at too low a value to show up on the graph. The priors for $q_g$ are uniform on a log-scale, and so the probability density function is $1/(x(b-a))$ on a linear scale (where $a=-5$ and $b=12$ are the bounds on the log scale), such that half of the weight of the prior distribution lies $>0.03$ [**for the parameters used in YMR], which is not obvious from the graphs. *** Parameter values are loaded automatically from the Awatea output, but if the distributions change type or parameters are fixed/estimated (except M's) then need to manually change priorDistList[[]] in ymrScape.r.}

\clearpage

\ymrfig{selectivityMCMC}{**** MCMC selectivity figure will go here, haven't calculated yet (started in {\tt plotSelMCMC.r}) but leave for now to get writing. This is just a placeholder ******}

\ymrfig{pdfBiomass1}{Marginal posterior densities for beginning year female spawning biomass (1000 tonnes) for years 1940-1963 for run \Sexpr{model.name}. Horizontal axes are all to same scale. Note that vertical axes are not to the same scale, but each is scaled to the peak of the density; with the area under each curve integrating to 1.0. Vertical lines are 2.5, 50 and 97.5 percentiles, and filled red circle indicates MPD value.}

\ymrfig{pdfBiomass2}{As for Figure \ref{fig:pdfBiomass1} for years 1964-1987.}

\ymrfig{pdfBiomass3}{As for Figure \ref{fig:pdfBiomass1} for years 1988-2011.}

\ymrfig{pdfRecruitment1}{Marginal posterior densities for recruitment for years 1940-1963 for run \Sexpr{model.name}. Horizontal axes are all to same scale, such that large recruitments in certain large years can be seen. Note that vertical axes are not to the same scale, but each is scaled to the peak of the density; areas under each curve will integrate to 1.0. Vertical lines are 2.5, 50 and 97.5 percentiles, and filled red circle indicates MPD value. }

\ymrfig{pdfRecruitment2}{As for Figure \ref{fig:pdfRecruitment1} for years 1964-1987.}

\ymrfig{pdfRecruitment3}{As for Figure \ref{fig:pdfRecruitment1} for years 1988-2011.}

\ymrfig{recruitsMCMC}{Marginal posterior distribution of recruitment in 1000's of age 1 fish plotted over time for run \Sexpr{model.name}. The boxes give the 2.5, 25, 50, 75 and 97.5 percentiles from the MCMC results.}

\ymrfig{exploitMCMC}{Marginal posterior distribution of exploitation rate plotted over time for run \Sexpr{model.name}. The boxes give the 2.5, 25, 50, 75 and 97.5 percentiles from the MCMC results.}

\ymrfig{VBcatch}{Vulnerable biomass (boxplots) and commercial catch (vertical bars) over time for run \Sexpr{model.name}. Boxplots show the 2.5, 25, 50, 75 and 97.5 percentiles from the MCMC results. Catch is shown to compare its magnitude to the estimated vulnerable biomass.}

\ymrfig{BVBnorm}{Changes in $B_t / B_0$ and $V_t / V_0$ (spawning and vulnerable biomass relative to virgin levels) over time for run \Sexpr{model.name}, shown as the medians of the MCMC posteriors.}

\clearpage 

\ymrfig{snail}{Trace through time of the medians of the ratios $B_t / B_\mathrm{MSY}$ (the spawning biomass in year $t$ relative to $B_\mathrm{MSY}$) and $u_t / u_\mathrm{MSY}$ (the exploitation rate in year $t$ relative to $u_\mathrm{MSY}$) for run \Sexpr{model.name}. Blue filled circle is the starting year (1940). Years then proceed from light grey through to dark grey with the final year (2010) as a filled red circle, and the red lines represent the 10\% and 90\% percentiles of the posterior distributions for the final year. Vertical grey lines indicate the provisional limit and upper stock reference points of 0.4$B_\mathrm{MSY}$ and 0.8$B_\mathrm{MSY}$, and horizontal grey line indicates $u_\mathrm{MSY}$.}

\ymrfig{Bproj}{Projected biomass under different constant catch strategies for run \Sexpr{model.name}~(boxplots show the 2.5, 25, 50, 75 and 97.5 percentiles from the MCMC results). For each of the 1000 samples from the MCMC posterior, the model was run forward in time (red) with a constant catch, and recruitment was simulated from the stock-recruitment function with lognormal error (see equation F.24). For reference, the average catch over the last five years (2006-2010) is 1442~t.}

\ymrfig{Rproj}{Projected recruitments under different constant catch strategies for run \Sexpr{model.name}~(boxplots show the 2.5, 25, 50, 75 and 97.5 percentiles from the MCMC results). This shows that the random projected recruitments are fairly similar from year-to-year, without the large recruitment events that are seen in the past. While individual MCMC simulations may have occasional large recruitments, this will not happen for a particular year for all MCMC simulations concurrently, which did happen in the past (so, in particular, the lowest estimates of recruitment were still high).}
% xx = apply(currentProj$R$'0', 2, max)
% summary(xx)
  
\ymrfig{Rproj1500}{Projected recruitments for just 1500 t constant catch strategy (to go into SAR) for run \Sexpr{model.name}~(boxplots show the 2.5, 25, 50, 75 and 97.5 percentiles from the MCMC results). This shows that the random projected recruitments are fairly similar from year-to-year, without the large recruitment events that are seen in the past. While individual MCMC simulations may have occasional large recruitments, this will not happen for a particular year for all MCMC simulations concurrently, which did happen in the past (so, in particular, the lowest estimates of recruitment were still high). The mean of the median historical recruitments is \Sexpr{round(meanRecMed, digits=0)}, whereas the mean of the median projected recruitments is \Sexpr{round(meanRecProjMed1500, digits=0)}.}
% xx = apply(currentProj$R$'1500', 2, median)
% mean(xx)   
% yy = apply(currentMCMC$R, 2, median)
% mean(yy)


\clearpage     % to get tables at end

\begin{table}[tp]
\centering
\caption{\label{tab:MCMCpar} 
Summary statistics of MCMC results for estimated parameters for run \Sexpr{model.name}. Parameters are defined in Appendix F. Except for $M_1$ and $M_2$, subscripts 1 to 5 correspond to the fishery-independent surveys, and subscript 6 to the commercial fishery.}
\begin{tabular}{lrrr} 
\hline
Parameter & \multicolumn{3}{c}{Percentile}\\
\cline{2-4}
 & 5\% & 50\% & 95\% \\
\hline 
$R_0$    & \Sexpr{qtab(currentMCMC$P$R_0)} \\
$M _ 1$  & \Sexpr{ if(length(currentMCMC$P$M_1) > 0) qtab(currentMCMC$P$M_1,dig=4) else  print(paste( "- & - & -", collapse = "")) } \\
$M _ 2$  & \Sexpr{ if(length(currentMCMC$P$M_2) > 0) qtab(currentMCMC$P$M_2,dig=4)  else  print(paste( "- & - & -", collapse = "")) } \\
$h$        & \Sexpr{qtab(currentMCMC$P$h, dig=3)} \\
$q_1$      & \Sexpr{qtab(currentMCMC$P$q_1, dig=5)} \\
$q_2$      & \Sexpr{qtab(currentMCMC$P$q_2, dig=5)} \\
$q_3$      & \Sexpr{qtab(currentMCMC$P$q_3, dig=5)} \\
$q_4$      & \Sexpr{qtab(currentMCMC$P$q_4, dig=5)} \\
$q_5$      & \Sexpr{qtab(currentMCMC$P$q_5, dig=5)} \\
$\mu_1$    & \Sexpr{qtab(currentMCMC$P$mu_1, dig=1)} \\
$\mu_2$    & \Sexpr{qtab(currentMCMC$P$mu_2, dig=1)} \\
$\mu_6$    & \Sexpr{qtab(currentMCMC$P$mu_6, dig=1)} \\
$\Delta_1$ & \Sexpr{qtab(currentMCMC$P$Delta_1, dig=2)} \\
$\Delta_2$ & \Sexpr{qtab(currentMCMC$P$Delta_2, dig=2)} \\ 
$\Delta_6$ & \Sexpr{qtab(currentMCMC$P$Delta_6, dig=2)} \\
$\log v_{1L}$  & \Sexpr{qtab(currentMCMC$P$"log v_1L", dig=2)} \\
$\log v_{2L}$  & \Sexpr{qtab(currentMCMC$P$"log v_2L", dig=2)} \\
$\log v_{6L}$  & \Sexpr{qtab(currentMCMC$P$"log v_6L", dig=2)} \\
\hline
\end{tabular}	
\end{table}



\begin{table}[tp]
\centering
\caption{\label{tab:MCMCderived} MCMC-derived quantities for run \Sexpr{model.name}, from each sample of the MCMC posterior. A maximum exploitation rate $u_{max}$ is calculated for each sample as the maximum exploitation rate from 1940-2010. For reference, the average catch over the last five years (2006-2010) is 1442~t.}
\medskip
\begin{tabular}{lrrr} 
\hline
Value & \multicolumn{3}{c}{Percentile}\\
\cline{2-4}
 & 5\% & 50\% & 95\% \\
\hline 
 & & & \\
& \multicolumn{3}{c}{From model output}\\
$B_0$                  & \Sexpr{qtab(B0.MCMC)} \\
$V_0$                  & \Sexpr{qtab(VB0.MCMC)} \\
$B_{\Sexpr{Year0}}$             & \Sexpr{qtab(Bcurr.MCMC)} \\
$V_{\Sexpr{Year0}}$             & \Sexpr{qtab(VBcurr.MCMC)} \\

$B_{\Sexpr{Year0}} / B_0$       & \Sexpr{qtab(Bcurr.MCMC / B0.MCMC, dig=3)} \\
$V_{\Sexpr{Year0}} / V_0$     & \Sexpr{qtab(VBcurr.MCMC / VB0.MCMC, dig=3)} \\

$u_{\Sexpr{Year0-1}}$             & \Sexpr{qtab(ucurr.MCMC, dig=3)} \\
$u_\mathrm{max}$       & \Sexpr{qtab(umax.MCMC, dig=3)} \\
\hline
 & & & \\
& \multicolumn{3}{c}{MSY-based quantities}\\
$0.4 B_\mathrm{MSY}$   &  \Sexpr{qtab(0.4*Bmsy.MCMC)} \\
$0.8 B_\mathrm{MSY}$   &  \Sexpr{qtab(0.8*Bmsy.MCMC)} \\
$B_\mathrm{MSY}$       &  \Sexpr{qtab(Bmsy.MCMC)} \\
$B_\mathrm{MSY} / B_0$ &  \Sexpr{qtab(Bmsy.MCMC / B0.MCMC, dig=3)} \\
$B_{\Sexpr{Year0}} / B_\mathrm{MSY}$ & \Sexpr{qtab(Bcurr.MCMC / Bmsy.MCMC, dig=3)} \\

$\mathrm{MSY}$                    & \Sexpr{qtab(msy.MCMC)} \\
$u_\mathrm{MSY}$       & \Sexpr{qtab(umsy.MCMC, dig=3)} \\
$u_{\Sexpr{Year0-1}} / u_\mathrm{MSY}$ & \Sexpr{qtab(ucurr.MCMC / umsy.MCMC, dig=3)} \\

$V_\mathrm{MSY}$       & \Sexpr{qtab(VBmsy.MCMC)} \\
$V_\mathrm{MSY} / V_0$ & \Sexpr{qtab(VBmsy.MCMC / VB0.MCMC, dig=3)} \\
\hline
\end{tabular}	
\end{table}


<<results=tex, echo=FALSE>>=
# xtable(matrix( c( hbigeye100$counts), ncol=4, byrow=TRUE), digits = 0, caption="Counts for 1-100, showing every 4th seems to be higher, with every 8th being way higher.")

tabdigits = 2      # number of decimal places to give
print(xtable(refProbs5$LRP, caption="Decision table concerning the limit reference point $0.4 \\Bmsy$ for 1-5 year projections for run MODEL.NAME for a range of constant catch strategies (in tonnes). Values are P$(B_t > 0.4 \\Bmsy)$, i.e.~the probability of the spawning biomass at the start of year $t$ being greater than the limit reference point. The probabilities are based on the MCMC posterior distributions of $B_t$ and $\\Bmsy$, and are rounded to two decimal places. [Table done automatically, can add extra details (as for POP) for final write up.]", label="tab:LRP5", digits=tabdigits), caption.placement="top") 
# it didn't like \Sexpr in caption=""

print(xtable(refProbs5$URP, caption="Decision table for the upper reference point $0.8 \\Bmsy$ for 1-5 year projections for run MODEL.NAME, such that values are P$(B_t > 0.8 \\Bmsy)$.", label="tab:URP5", digits=tabdigits), caption.placement="top")

# print(xtable(refProbs5$Bmsy, caption="Decision table for MSY for 1-5 year projections for run MODEL.NAME, such that values are P$(B_t > \\Bmsy)$.", label="tab:Bmsy5", digits=tabdigits), caption.placement="top")

print(xtable(refProbsB05$B00.2, caption="Decision table for the alternative limit reference point $0.2 B_0$ for 1-5 year projections for run MODEL.NAME, such that values are P$(B_t > 0.2 B_0)$.", label="tab:B00.2.5yr", digits=tabdigits), caption.placement="top")

print(xtable(refProbsB05$B00.4, caption="Decision table for the alternative upper reference point $0.4 B_0$ for 1-5 year projections for run MODEL.NAME, such that values are P$(B_t > 0.4 B_0)$.", label="tab:B00.4.5yr", digits=tabdigits), caption.placement="top")

print(xtable(refProbs3Gen5$'0.5Gen3', caption="Decision table for probabilities of satisfying the criterion of $\\leq 50 \\%$ decline over three generations, for 1-5 year projections for run MODEL.NAME. Three generations is 90 years, and since $B_0$ is the estimated spawning biomass in 1940 and projections here are only up to 5 years, the probabilites here are simply equal to P$(B_t > 0.5 B_0)$.", label="tab:0.5Gen3.5yr", digits=tabdigits), caption.placement="top")

print(xtable(refProbs3Gen5$'0.7Gen3', caption="Decision table for probabilities of satisfying the criterion of $\\leq 30 \\%$ decline over three generations, for 1-5 year projections for run MODEL.NAME. Three generations is 90 years, and since $B_0$ is the estimated spawning biomass in 1940 and projections here are only up to 5 years, the probabilites here are simply equal to P$(B_t > 0.7 B_0)$.", label="tab:0.7Gen3.5yr", digits=tabdigits), caption.placement="top")
             
           

# print(xtable(refProbsB05$B00.5, caption="Decision table for reference point $0.5 B_0$ for 1-5 year projections for run MODEL.NAME, such that values are P$(B_t > 0.5 B_0)$.", label="tab:B00.5.5yr", digits=tabdigits), caption.placement="top")

# print(xtable(refProbsB05$B00.7, caption="Decision table for reference point $0.7 B_0$ for 1-5 year projections for run MODEL.NAME, such that values are P$(B_t > 0.7 B_0)$.", label="tab:B00.7.5yr", digits=tabdigits), caption.placement="top")

print(xtable(refProbs90$LRP, caption="Decision table for the limit reference point $0.4 \\Bmsy$ for every 15th year (starting from 2011) of 90-year projections for run MODEL.NAME, such that values are P$(B_t > 0.4 \\Bmsy)$.", label="tab:LRP90", digits=tabdigits), caption.placement="top") 

print(xtable(refProbs90$URP, caption="Decision table for the upper reference point $0.8 \\Bmsy$ for every 15th year of 90-year projections for run MODEL.NAME, such that values are P$(B_t > 0.8 \\Bmsy)$.", label="tab:URP90", digits=tabdigits), caption.placement="top")

print(xtable(refProbsB090$B00.2, caption="Decision table for the alternative limit reference point $0.2 B_0$ for 90-year projections for run MODEL.NAME, such that values are P$(B_t > 0.2 B_0)$.", label="tab:B00.2.90yr", digits=tabdigits), caption.placement="top")

print(xtable(refProbsB090$B00.4, caption="Decision table for the alternative upper reference point $0.4 B_0$ for 90-year projections for run MODEL.NAME, such that values are P$(B_t > 0.4 B_0)$.", label="tab:B00.4.90yr", digits=tabdigits), caption.placement="top")

print(xtable(refProbs3Gen90$'0.5Gen3', caption="Decision table for probabilities of satisfying the criterion of $\\leq 50 \\%$ decline over three generations for 90-year projections for run MODEL.NAME. The probabilites are P$(B_t > 0.5 B_{t-90})$.", label="tab:0.5Gen3.90yr", digits=tabdigits), caption.placement="top")

print(xtable(refProbs3Gen90$'0.7Gen3', caption="Decision table for probabilities of satisfying the criterion of $\\leq 30 \\%$ decline over three generations for 90-year projections for run MODEL.NAME. The probabilites are P$(B_t > 0.7 B_{t-90})$.", label="tab:0.7Gen3.90yr", digits=tabdigits), caption.placement="top")

print(xtable(Ttab0.5, caption="Estimated time (years) to be above each reference point or achieve each target with a probability of 50\\%, for each constant catch strategy and for run MODEL.NAME. An estimated time of 0 means that the condition is currently satisfied and remains so over the 90-year projection; an estimated time of 90 means that the condition never becomes satisfied over the 90-year projection. A further condition is that the probability of satisfying the condition must increase for two consecutive years. Columns respectively correspond to reference points $0.4 \\Bmsy, 0.8 \\Bmsy, 0.2 B_0, 0.4 B_0$ and to the criteria of $\\leq 50 \\%$ decline and $\\leq 30 \\%$ decline over three generations.", label="tab:Ttab0.5", digits=0), caption.placement="top")

print(xtable(Ttab0.8, caption="Estimated time to be above each reference point or achieve each target with a probability of 80\\%, for each constant catch strategy and for run MODEL.NAME. See Table \\ref{tab:Ttab0.5} for column definitions.", label="tab:Ttab0.8", digits=0), caption.placement="top")

print(xtable(Ttab0.95, caption="Estimated time to be above each reference point or achieve each target with a probability of 95\\%, for each constant catch strategy and for run MODEL.NAME. See Table \\ref{tab:Ttab0.5} for column definitions.", label="tab:Ttab0.95", digits=0), caption.placement="top")




# print(xtable(refProbsB090$B00.5, caption="Decision table for reference point $0.5 B_0$ for 90-year projections for run MODEL.NAME, such that values are P$(B_t > 0.5 B_0)$.", label="tab:B00.5.90yr", digits=tabdigits), caption.placement="top")

# print(xtable(refProbsB090$B00.7, caption="Decision table for reference point $0.7 B_0$ for 90-year projections for run MODEL.NAME, such that values are P$(B_t > 0.7 B_0)$.", label="tab:B00.7.90yr", digits=tabdigits), caption.placement="top")




# print(xtable(refProbs20$LRP, caption="Decision table for the lower reference point $0.4 \\Bmsy$ for every 5th year of 20-year projections for run MODEL.NAME, such that values are P$(B_t > 0.4 \\Bmsy)$.", label="tab:LRP20", digits=tabdigits), caption.placement="top")

# print(xtable(refProbs20$URP, caption="Decision table for the upper reference point $0.8 \\Bmsy$ for every 5th year of 20-year projections for run MODEL.NAME, such that values are P$(B_t > 0.8 \\Bmsy)$.", label="tab:URP20", digits=tabdigits), caption.placement="top")

# print(xtable(refProbs20$Bmsy, caption="Decision table for $\\Bmsy$ for every 5th year of 20-year projections for run MODEL.NAME, such that values are P$(B_t > \\Bmsy)$.", label="tab:Bmsy20", digits=tabdigits), caption.placement="top")

@ 



\end{document}

% CUT HERE 


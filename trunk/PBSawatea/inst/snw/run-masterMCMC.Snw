% From Rowan's run-masterMCMC-rh14aug12.Snw. 
% ymrrun-masterMCMC.Snw - just doing MCMC output (MCMC lines were 
%  commented out in ymrrun-masterMCMC.Snw). AME, 3rd May 2011
% ymrrun5-0.Snw. 5/4/11.
% ymrrun2-5.Snw - from Rowan's run2 output. Fifth reweighting. Also
%  adding in automatic table of parameter values. 28th March 2011
% ymrrun1dos.Snw - automatically plot MPD output from Awatea, using
%  scape. Awatea results.dat file must be in directory above, this
%  one used just for figures. 23rd Feburary 2011

\documentclass[12pt]{article}

\usepackage{Sweave}   % andy add3ed
\usepackage{epsfig}
\usepackage{rotating}    % for sideways table
\usepackage{longtable}
% \usepackage{placeins}
% \usepackage{nccmath}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry} 


\newcommand{\eb}{\begin{eqnarray}}
\newcommand{\ee}{\end{eqnarray}}
\renewcommand{\baselinestretch}{1.0}
\newcommand{\Bmsy}{B_\mathrm{MSY}}

% For write up
\def\AppLet{G}                   % Appendix letter
\def\StartP{100}                   % page start

\renewcommand{\theequation}{\AppLet.\arabic{equation}}
\renewcommand{\thefigure}{\AppLet.\arabic{figure}}

\renewcommand{\rmdefault}{phv}   % Arial
\renewcommand{\sfdefault}{phv}   % Arial


\newcommand\ymrfig[2]{    % filename is #1, text is #2
  \begin{figure}[htp]
  \begin{center}
  \epsfxsize=6in
  \epsfbox{#1.eps}
  \end{center}
  \caption{#2 }
  \label{fig:#1} 
  \end{figure}
  % \clearpage  
}

\newcommand\twofig[3]{    % figure #1 under #2, caption text #3
  \begin{figure}[htp]            %  label will be #1
  \centering
  \begin{tabular}{c}
  \epsfbox{#1.eps} \\
  \epsfbox{#2.eps}
  \end{tabular}
  \caption{#3}
  \label{fig:#1}
  \end{figure}
}

\SweaveOpts{pdf=FALSE}        % keep.source=TRUE, 
% Most useful options (with defaults):
% echo = TRUE  - includes R code in output file
% keep.source = FALSE - when echoing, if TRUE then original source is
%  copied to the file, otherwise deparsed source is echoed.
% eval = TRUE - if FALSE then chunk is not evaluated
% results = verbatim - R output included verbatim, if tex output is 
%  already proper latex and included as is, if hide then all output
%  is completely suppressed (but the code executed - good for admb)
%  Must be lower case (unlike the others!).
% pdf = TRUE - whether .pdf figures shall be generated
% eps = TRUE - whether .eps figures shall be generated
% strip.white = FALSE - if true then blank lines at beginning and
%  end of output are removed. If all, then all blank lines are removed.
% width = 6  - width of figures in inches
% height = 6 - height of figures in inches
% fig = FALSE - whether the code chunk produces graphical output 
%  (only one per chunk)
% \setkeys{Gin}{width=6in}     % from googling sweave figure bigger.
%  It will set this for the rest of document 
%  [doesn't width do that in the above?]

\begin{document}
\setcounter{page}{\StartP}

\begin{center}

{\Large \bf POP 3CD MCMC working results}

\vspace{7mm}

{\Large \bf Andrew M.~Edwards, Rowan Haigh and Paul J.~Starr}

% This file started 5th April 2011.

Latest is \today, with \Sexpr{print(version$version.string)}. 
% \Sexpr{print(version$platform)}.

% {\tt Andrew.Edwards@dfo-mpo.gc.ca}

% \vspace{4mm}

\end{center}

% First set up workspace:
<<setupworkspace, echo=FALSE, results=hide>>= # hide the results 
cwd = "@cwd"            # Top level directory; all models occur below this one. 

@ 

% '@variables' replaced by function 'runSweave' to create individual Sweaves for runs and reweightings.
<<modelname, echo=FALSE>>=
model.name     = "@model.name"
run.dir        = "@run.dir"
fig.dir        = "@fig.dir"
msy.dir        = "@msy.dir"
prj.dir        = "@prj.dir"
running.awatea = @running.awatea   # 0 if just loading previous '.rep'; 1 if rerunning Awatea. 
@ 
<<awatea.run, results=hide, echo = FALSE>>=
if(running.awatea) {
  setwd(run.dir)
  shell( paste("awatea -ind ", model.name,".txt -nohess", sep=""))
  #  HAVE to do hess for MCMC
  # shell(     - copy results.dat to results model.name .dat)
  setwd(cwd)     # back to current directory
  } 
@ 

\pagestyle{myheadings}
\markright{\Sexpr{paste("From MCMC", model.name, sep="")}}

Plotting MCMC output for model {\tt \Sexpr{model.name}}. 
% Loading in *****{\tt \Sexpr{model.name}.***} file, that has already been created.

% We {\bf are}~{\bf \Sexpr{if(!running.awatea) paste("NOT")}} re-running Awatea here\Sexpr{if(!running.awatea) paste(" so just loading in outputNOT")}.

% If editing {\tt .txt} file, may have to rerun just in dos/R first to check the output from ADMB (otherwise errors get hidden): 

% {\tt > shell( paste("awatea -ind ../", model.name,".txt -nohess", sep=""))}

\section{History of Runs}


{\tt Run01}: 1 survey (WCVI Syn + US Triennial stitched just to get something running), no CPUE series, estimating $R_0$ and $q$ only, initial run with many POP QCS defaults. \newline  

\noindent {\tt Run02}: Same as {\tt Run01}, but estimating all parameters. Tried extra reweightings to see if they made a difference (because average weights looked a worse fit for first reweighting than no reweighting). For ageing data, first reweight downweights survey effective sample size (originally 10, 8, 8, 29), first reweight is 15\% of that (so fit is worse). Commercial increases to 1.73 times, so it somewhat prefers that data. \newline

\noindent {\tt Run03}: From Paul (his {\tt InputPOP wcvi 05A.txt}), 25/7/12. Now starts from 1976, many (but not all) of the parameters estimated. Gives moderately sensible results. Contains the 17 CPUE indices and the 1996 Caledonian survey estimate. Now estimating {\tt log init devs}: deviates for initial age structure; {\tt initial R}: number 1-year olds in year 1 relative to $R_0$ (**perhaps); {\tt initial u}: exploitation for initial age structure (one for each sex); {\tt plus scale}: multiplier on the "plus" group, which recognises that the cumulative exploitation on the plus group will exceed the estimate made by the parameter 'initial u' (one parameter for each sex). Find $R_0 \simeq 1700$, {\tt uinit}$\simeq 0.01$ and the plus-scale is a very small number. I don't think these make sense.  It may be a better idea to not estimate plus-scale at this point.  And {\tt Rinit}$>1$, which also seems silly. It's still early days, but it looks like this approach will lead to an assessment, which is good news. \newline

\noindent {\tt Run04}: Same as {\tt Run03}, but setting priors for natural mortality to Normal(0.067, sd$=$0.0029) for females, Normal(0.073, 0.0031) for males, based on posteriors of QCS POP assessment. May want to (i) use one prior for both sexes (Normal(0.07, 0.003)), or (ii) make priors broader. Take out 1996 synoptic survey index that was included (it was targetting POP and caught POP about twice as frequently as the later cruises - see Paul's Appendix C). Also using priors for selectivity parameters based on posteriors from QCS (see {\tt POP12SelPrior.pdf}), which works out normal distribution priors. I noticed in the previous input file these were set as uniforms, but I've changed to normals which seems to work. \newline

\noindent {\tt Run05}: Same as {\tt Run04} with changes: (1) log init devs changed from phase 3 to phase 2. (2) Tried changing 'Survey catch at age likelihood type' survey1 to '0' (from 12), with dummy set of catch-at-age data for survey1 (this gives the same par and MPD estimates but throws the indexing off for catch-at-age fits; therefore reverted to one catch-at-age series with no dummy). (3) Updated the WCVI synoptic survey biomass estimates to reflect some minor changes in all of them, except for 2010 survey which has changed a lot. \newline

\noindent {\tt Run06}: Upon the advice of the POP working group (meeting 2012-08-01) the age composition was shortened to 30 age bins, where 30 acts as a plus class. Also in this run, a third survey series (GB Reed: 1967-70) was added. Note that Awatea currently has an indexing bug in the output routine regarding survey (and possibly commercial) catch-at-age fits. Therefore, the last survey (WCVI Synoptic) is labelled the first (and survey 2 = NMFS Triennial, survey 3 = GB Reed). \newline

\noindent {\tt Run07}: Same as {\tt Run06} except for placing priors on natural mortality and selectivity. $M_1$ and $M_2$ are fixed to the mean of the prior, steepness $h$ is fixed.  \newline

\noindent {\tt Run08}: Same as {\tt Run07} except $M_1, M_2$ and $h$ are estimated. \newline

Not fully automated: 

- Table of summary statistics (switches fine if $M_s$ and/or $h$ are fixed/estimated, but won't add extra parameters in (fine for 3CD, will have to tweak for 5DE). 

- pairs plots, need to comment in/out inclusion of figures depending on numbers of parameters.

- ignore the final few tables, which I haven't checked yet (it just blanks them, presumably as the values are not calculated).

\medskip

% \noindent Using Run29 and Run30 as 'Estimate $M$' and 'Fix $M$' main runs in YMR write-up, with Run24 and Run28 mentioned in as sensitivites to including simple ageing error.


<<fromscape, results=hide, echo=FALSE>>=
# Commenting some out for ymr.
#--------------------------------------------------------------------#   AME Commands that are actually run.

# Set style of reconstruction-projection plots.
# Options: "lines", "lineDot", "quantBox"
rpType <- "quantBox"

trellis.device(device="postscript", color=TRUE)   # for colour .eps

# Load in .res file.
setwd(fig.dir) 
#currentRes <- importCol2(paste("../", model.name, ".res", sep=""), 
currentRes = importRes(paste(run.dir,"/", model.name, ".res",sep=""),
             Dev=TRUE, CPUE=TRUE, Survey=TRUE, 
             CLc=TRUE, CLs=TRUE, CAs=TRUE, CAc=TRUE, extra=TRUE)
# maybe should be CPUE=cpue

years = currentRes$B[,"Year"]    
sigmaR = currentRes$extra$residuals$p_log_RecDev[6]
    # to use when importing projected recruitment deviations (that
    #  are actually just the random N(0,1) numbers so need 
    #  multiplying by sigmaR).

# Assign a generic title for use in some plots.
mainTitle <- "@sppname"

# Minimum data year for tuning index.
# minCpueYr <- 1940
#ACH: I'm not sure exactly what this is for but I set it to the start year

# Awatea MCMC.
currentMCMC <- importMCMC( dir=".", quiet=FALSE )
assign( "currentMCMC", currentMCMC, pos=1 )

num.MCMC = dim(currentMCMC$P)[1]     # number of MCMC samples
# currentMCMCorig = currentMCMC  
       # to use below
# importMCMC (a scape function) seems to get years wrong on the recruitment, see popScape2.r for details, here is the fix
names(currentMCMC$R) = as.integer(names(currentMCMC$R)) + 1
                                        #currentRes$B$R seems one off
# Also change names of estimated parameters to those matching my
#  write up, and change to the same order. See POPscape2.r .
# **** AME hard-wiring cannot work; RH attempt to fix: ***
#==========================================================
# Get the commercial and survey index series
Cser=unique(currentRes$CPUE$Series);   NCser=length(Cser)
# There has to be a dummy CPUE series in the input, but the 
#  likelihood switch says whether it is being fitted. Seems
#  that the calculated likelihood is 0 if not fitted:
if(currentRes$extra$likelihoods$CPUE == 0) { NCser = 0 }
if(NCser > 1) stop("priorInput construction assumes one CPUE 
  series so needs updating in run-masterMCMC.Snw")

Sser=unique(currentRes$Survey$Series); NSser=length(Sser)

# Get the commercial and survey age series
# These might also need fixing if there are dummy data that
#  aren't being fitted.
CAser=unique(currentRes$CAc$Series);   NCAser=length(CAser)
SAser=unique(currentRes$CAs$Series);   NSAser=length(SAser)

Ncomm = max(NCser,NCAser) # number of commercial series w/ data/ages
Nsurv = max(NSser,NSAser) # number of survey series with data/ages

Pnames = names(currentMCMC$P)
# can take out paste once get updated PBSawatea.
new.Pnames = gsub("M1_2",paste("M_",2,sep=""),sub("M1_1",paste("M_",1,sep=""),sub("R0","R_0",Pnames)))
for (i in 1:Ncomm) {
	ii = i + Nsurv
	new.Pnames = sub(paste("Sfullest_",i,sep=""),paste("mu_",ii,sep=""),new.Pnames)
	new.Pnames = sub(paste("log_varLest_",i,sep=""),paste("log v_",ii,"L",sep=""),new.Pnames)
	new.Pnames = sub(paste("Sfulldelta_",i,sep=""),paste("Delta_",ii,sep=""),new.Pnames)
	new.Pnames = sub(paste("log_qCPUE_",i,sep=""),paste("log q_",ii,sep=""),new.Pnames)
}
for (i in 1:Nsurv) {
	ii = Sser[i]
	new.Pnames = sub(paste("surveySfull_",i,sep=""),paste("mu_",ii,sep=""),new.Pnames)
	new.Pnames = sub(paste("log_surveyvarL_",i,sep=""),paste("log v_",ii,"L",sep=""),new.Pnames)
	new.Pnames = sub(paste("surveySfulldeltaest_",i,sep=""),paste("Delta_",ii,sep=""),new.Pnames)
	new.Pnames = sub(paste("log_qsurvey_",i,sep=""),paste("log q_",ii,sep=""),new.Pnames)
}
new.Pnames = sub("log_BetaCPUE","log beta",new.Pnames)
# Probably want to change beta, as have beta in write-up already
#  with respect to SR function. And un-log it. Just another q? Think
#  that's already done above - check when doing on a CPUE one. No,
#  I think it's the power for the CPUE.

# Use this if adding extra parameters that are estimated that
#  we haven't thought of here. This is the global list in the
#  desired order. If >5 surveys then expand this, and expand 
#  priorInput function below.
tab.Pnames = c("R_0","M_1","M_2","h",
  paste("log q_",1:(Nsurv+Ncomm),sep=""),"log beta", 
  paste("mu_",1:(Nsurv+Ncomm),sep=""),
  paste("Delta_",1:(Nsurv+Ncomm),sep=""),
  paste("log v_",1:(Nsurv+Ncomm),"L",sep=""))

# Put them into the standard order:
use.Pnames = tab.Pnames[is.element(tab.Pnames,new.Pnames)]

if(length(use.Pnames) != length(new.Pnames))
  {stop("Check tab.Pnames in run-masterMCMC.Snw")}

# Assign new names
names(currentMCMC$P) = new.Pnames    
# Re-order to match Paul's results table 3:
currentMCMC$P = currentMCMC$P[,use.Pnames]
@

<<priors, results=hide, echo=FALSE>>=

# Importing and defining prior functions for general model runs.
#  If change tab.Pnames above then change some of priorInput.

# Unlogging q's at the end

priorFunc = function(input.prior) 
  { switch(as.character(input.prior[4]),
       "0" = function(x, input.prior) { dunif(x, min =
          input.prior[2], max =  input.prior[3]) },
       "1" = function(x, input.prior) { dnorm(x, mean = input.prior[5], sd = input.prior[6]) },
       "2" = stop("figure out lognormal in priorFunc"),
       "5" = function(x, input.prior) { dbeta(x, shape1 = , input.prior[5], shape2 = input.prior[6]) } )
  }

priorInput = array(dim = c(length(use.Pnames), 7))
              # array of priors from the input file, going to put
              #  into the order of use.Pnames
priorDistList = list()      # should be length of use.Pnames
for(i in 1:length(use.Pnames)) 
  {
     ii = use.Pnames[i]
     priorInput[i,] =
     switch(ii,
       # This covers all choices in tab.Pnames
       "R_0" = currentRes$extra$priors$R0,
       "M_1" = currentRes$extra$priors$M1_prior[1,],
       "M_2" = currentRes$extra$priors$M1_prior[2,],            
       "h"   = currentRes$extra$priors$h_prior,              
       "log q_1" = currentRes$extra$priors$log_qsurvey_prior[1,],
       "log q_2" = if(Nsurv > 1.9)     # 2 or more surveys
           { currentRes$extra$priors$log_qsurvey_prior[2,] } else
           { currentRes$extra$priors$log_qCPUE_prior },
         # if use.Pnames has q_2 but there's only 1 survey, then
         #  q_2 is the CPUE index catchability. Assuming only
         #  one CPUE index - error message given above if more.
       "log q_3" = if(Nsurv > 2.9)
           { currentRes$extra$priors$log_qsurvey_prior[3,] } else
           { currentRes$extra$priors$log_qCPUE_prior },
       "log q_4" = if(Nsurv > 3.9)
           { currentRes$extra$priors$log_qsurvey_prior[3,] } else
           { currentRes$extra$priors$log_qCPUE_prior },
       "log q_5" = if(Nsurv > 4.9)
           { currentRes$extra$priors$log_qsurvey_prior[3,] } else
           { currentRes$extra$priors$log_qCPUE_prior },
       # assume here max 5 survey series and so CPUE series is 6.
       #  Next line gets ignored if <5 surveys as it won't be
       #  in tab.Pnames anyway (since assuming only 1 CPUE)
       "log q_6" = currentRes$extra$priors$log_qCPUE_prior,
       "log beta" = currentRes$extra$priors$log_BetaCPUE_prior,
       "mu_1" = currentRes$extra$priors$surveySfull_prior[1,],
       "mu_2" = if(Nsurv > 1.9)
            { currentRes$extra$priors$surveySfull_prior[2,]} else
            { currentRes$extra$priors$p_Sfullest},
       "mu_3" = if(Nsurv > 2.9)
            { currentRes$extra$priors$surveySfull_prior[3,]} else
            { currentRes$extra$priors$p_Sfullest},
       "mu_4" = if(Nsurv > 3.9)
            { currentRes$extra$priors$surveySfull_prior[4,]} else
            { currentRes$extra$priors$p_Sfullest},
       "mu_5" = if(Nsurv > 4.9)
            { currentRes$extra$priors$surveySfull_prior[5,]} else
            { currentRes$extra$priors$p_Sfullest},
       # Again assume 5 surveys then correct below, this won't get
       #  get called if <5:
       "mu_6" = currentRes$extra$priors$p_Sfullest,
       "Delta_1" = currentRes$extra$priors$p_surveySfulldelta[1,],
       "Delta_2" = if(Nsurv > 1.9)
            { currentRes$extra$priors$p_surveySfulldelta[2,] } else
            { currentRes$extra$priors$p_Sfulldelta },
       "Delta_3" = if(Nsurv > 2.9)
            { currentRes$extra$priors$p_surveySfulldelta[3,] } else
            { currentRes$extra$priors$p_Sfulldelta },
       "Delta_4" = if(Nsurv > 3.9)
            { currentRes$extra$priors$p_surveySfulldelta[4,] } else
            { currentRes$extra$priors$p_Sfulldelta },
       "Delta_5" = if(Nsurv > 4.9)
            { currentRes$extra$priors$p_surveySfulldelta[5,] } else
            { currentRes$extra$priors$p_Sfulldelta },
       # Again assume 5 surveys.
       "Delta_6" = currentRes$extra$priors$p_Sfulldelta,
       "log v_1L" = currentRes$extra$priors$log_surveyvarL_prior[1,],
       "log v_2L" = if(Nsurv > 1.9)
            { currentRes$extra$priors$log_surveyvarL_prior[2,] } else
            { currentRes$extra$priors$log_varLest_prior},
       "log v_3L" = if(Nsurv > 2.9)
            { currentRes$extra$priors$log_surveyvarL_prior[3,] } else
            { currentRes$extra$priors$log_varLest_prior},
       "log v_4L" = if(Nsurv > 3.9)
            { currentRes$extra$priors$log_surveyvarL_prior[4,] } else
            { currentRes$extra$priors$log_varLest_prior},
       "log v_5L" = if(Nsurv > 4.9)
            { currentRes$extra$priors$log_surveyvarL_prior[5,] } else
            { currentRes$extra$priors$log_varLest_prior},
       # Again assume 5 surveys.
       "log v_6L" = currentRes$extra$priors$log_varLest_prior)
     priorDistList[[i]] = priorFunc(priorInput[i,])
   }
row.names(priorInput) = use.Pnames       
names(priorDistList) = use.Pnames

# confused that after running, those two have q_1 etc. but use.Pnames
#  does not.

# Now going to use q_1, q_2, q_3, not log q_1 etc. So rename
#  and then change values:
qnames = use.Pnames[grep("log q_",use.Pnames)]
for (i in qnames) {
	currentMCMC$P[,i] = exp(currentMCMC$P[,i])
        # exponentiates the MCMC values
}
names(currentMCMC$P)[is.element(names(currentMCMC$P),qnames)] = substring(qnames,5)

# Don't need to change tab.Pnames etc. as figures get labelled 
#  automatically from the names in currentMCMC$P

# Need to 'exponentiate' the priors and bounds for q
for(i in qnames) {
  if(priorInput[i,4] != 0) stop("need to exponentiate non-uniform priors for log q, in run-masterMCMC.Snw")
  # otherwise it's uniform.
  # Need to have the bounds exponentiated because the panel.curve
      #  plot uses them automatically to define the range. So change
      #  the priorInput bound values here, and change priorDistList 
      #  to use those because that's what will get called.
  priorInput[i,c(2,3,7)] = exp(priorInput[i,c(2,3,7)])   
                                   # 7 is init cdtn
  priorDistList[[i]] = function(x, input.prior) 
    {   # log x uniform between a and b, then pdf for x is
        #  1/(x (b-a)) between exp(a) and exp(b). Equivalently
        # A = exp(a), B = exp(b) gives pdf for x as
        # 1 /(x (log(B) - log(A)) between A and B
      (x*( log(input.prior[3]) - log(input.prior[2])))^(-1) * ((x >= input.prior[2]) & (x <= input.prior[3] ) ) }
  }  
# And rename priorInput and priorDistList.
row.names(priorInput)[is.element(row.names(priorInput),qnames)] = substring(qnames,5)
names(priorDistList)[is.element(names(priorDistList),qnames)] = substring(qnames,5)


# AME - I'd thought have to fix for beta also, but that's set to 0now
#  I think (had thought it was q, but it's the power).

# End RH fix
#==========================================================

# Deleting lots of commented out code, 20th August 2012.

# Also have to import vulnerable biomass from vulnBiom.pst, as it's
#  not done in importMCMC. Can just do as a data table. Has columns
#  representing years, and each of 1000 rows is an MCMC sample. Same
#  size as currentMCMC$B. It is
#  calculated as denominator of (D.11) in QCS POP model appendix.

vbMCMC = read.table("vulnBiom.pst", header=TRUE)
names(vbMCMC) = names(currentMCMC$B)      # to make them simply years
currentMCMC[["VB"]] = vbMCMC
       # Add to currentMCMC so that it gets called into functions.

# Awatea projection.
# The importProj function loads a list with elements "B" and "Y" for 
# biomass by catch policy and year, and catch by harvest policy and 
# year.  The "B" element is itself a list of matrices with a matrix 
# for each level of the catch.  This matrix has rows equal to the   
# length of the chain and columns corresponding to projection years.
# There are no [specific - AME] plotting routines for these data.    

# currentProj$eps is a list of data frames, one for each catch
#  strategy, though each data frame is the same (because the same
#  random N(0,1) are used for each one). Each data frame is 1000x91
#  as each row is an MCMC sample and each column is projected year,
#  from 2011 to 2101. For a given MCMC sample, the same random
#  numbers are used for each strategy (but random numbers are
#  different between MCMC samples). i.e.:
# > range(currentProj$eps$'0'[1,] - currentProj$eps$'0'[2,] )
# [1] -2.722770  2.844936
# > range(currentProj$eps$'0'[1,] - currentProj$eps$'250'[1,] )
# [1] 0 0
# So although the eps are the same for each strategy, the actual
#  recruitments won't be because the spawning biomassess will be
#  changing (first year should be the same though).

# currentProj <- importProj( dir=".", quiet=FALSE )

currentProj <- importProjRec( dir=prj.dir, quiet=FALSE )
   # importProjRec includes epsilons for recruitments
   # Then below we calcualte the actual recruitments.

assign( "currentProj", currentProj, pos=1 )
# Take off final year of projection
currentProj$B = lapply(currentProj$B, function(x) {  x[ ,1:(dim(x)[[2]]-1)]  })
currentProj$Y = lapply(currentProj$Y, function(x) { x[ ,1:(dim(x)[[2]]-1)]  })
currentProj$eps = lapply(currentProj$eps, function(x) {  x[ ,1:(dim(x)[[2]]-1)] })
# currentProj$R is calculated below
# sd(unlist(currentProj$eps$'0'))
# [1] 0.8993165
#  sd(unlist(currentProjaa$eps$'250'))
# [1] 0.8993165
#  etc., as they're all the same, and the sd equals sigmaR.


# Awatea MSY.
currentMSY <- msyCalc( dir=msy.dir, error.rep = 0 )
assign( "currentMSY", currentMSY, pos=1 )      # Forces it global (or something)

# Do these for ease of showing statistics in tables. Each should be a vector with value 
#  for each MCMC draw

if(currentRes$extra$priors$Rinit_prior[1] > 0 & currentRes$extra$priors$Rinit_prior[7] != 1) stop("Not starting from unfished equilibrium, so need to fix B0 values")
B0.MCMC = currentMCMC$B[,1]
# To calculate trajectory for Bt/B0 MCMC's, do:
# BoverB0 = currentMCMC$B / B0.MCMC     # B/B0  each chain
# BoverB0med = apply(BoverB0, 2, median)         # median each year

# AME changing RH's Year to currYearChar
currYearChar = rev(dimnames(currentMCMC$B)[[2]])[1]      
                # character current year (start for projections)
# AME changing RH's Year0 to currYear
currYear = as.numeric(currYearChar)         # numeric current year
startYearChar = dimnames(currentMCMC$B)[[2]][1]   # start year
startYear = as.numeric(startYearChar)

#Ypro  = dimnames(currentProj$B[[1]])[[2]]        # character available projection years
#Ypr0  = as.numeric(Ypro)                         # numeric available projection years

Bcurr.MCMC = currentMCMC$B[,currYearChar]
VB0.MCMC = currentMCMC$VB[,1]
VBcurr.MCMC = currentMCMC$VB[,currYearChar]
Bmsy.MCMC = currentMSY$B
VBmsy.MCMC = currentMSY$VB
msy.MCMC = currentMSY$yield
umsy.MCMC = currentMSY$u


# To calculate the actual projected recruitments (from the eps)
currentProj$R = list()
NN = matrix(1:num.MCMC, nrow=1)      # to use to populate each data.frame
projYearsNames = names(currentProj$B[[1]])
projYearsNum   = length(projYearsNames)

# First calculate recruits for first projection year, which is based
#  on penultimate MCMC year's spawners (which is 2010, final year
#  of that is 2011, first proj year is 2011, and I checked that
#  values for last year of MCMC equal those for first yr of proj:
#  > range(currentMCMC$B[, 72] - currentProj$B$'250'[, 1])
#      0 0.
# Do this here as does not depend on projections (and so is same for
#  all catch strategies).
Bpen.MCMC = currentMCMC$B[, rev(names(currentMCMC$B))[2]]
     # spawning biomass for penultimate year of MCMC


# Need a vector of h for projections, so if h not estimated
#  make hForProj just replicate the mpd value:

if (!is.element("h",use.Pnames))
  {hForProj = rep(currentRes$extra$parameters$h, num.MCMC) } else 
  { hForProj = currentMCMC$P$h }
  
RfirstProj = srFun(Bpen.MCMC, R0 = currentMCMC$P$R_0, h=hForProj, B0=B0.MCMC)

# Stochastic multiplier, will be same for all strategies as random
#  numbers currentProj$eps[[j]] are the same for each strategy j
stochMult = exp(currentProj$eps$'0' - sigmaR^2/2)

for(j in 1:length(currentProj$eps) )    # loop over policies
  {
  junk = apply(NN, 2, function(i, B, R0, h, B0) {
   srFun(as.numeric(B[i,]), h = h[i], R0=R0[i], B0=B0[i] ) },
   B = currentProj$B[[j]],
   R0 = currentMCMC$P$R_0, h = hForProj, B0=B0.MCMC)
       # Rowan's trick for using apply on each row.
  junk = t(junk)
  junk = as.data.frame(junk)
       # This gives data
       #  frame, rows are MCMC samples, columns are recruits for the
       #  next year. Need to insert RfirstProj as first column,
       #  and remove final column (which
       #  corresponds to recruits for the year after final projection
       #  year).
  detR = cbind(RfirstProj, junk)
  detR = detR[, -dim(detR)[2] ]     # take off final column
  names(detR) = projYearsNames      # detR is deterministic values
  stochR = detR * stochMult
  currentProj$R[[j]] = stochR
  }
names(currentProj$R) = names(currentProj$eps)

# Bmsy Reference points (could move this to scape at some point):

refPointsList = refPoints()  # ONLY set up for default 0.4, 0.8 
                    #  and 1 Bmsy at the moment *****
refProbsList = calc.refProbs() # currentMCMC$B, currentProj$B, refPointsList)
# That's a list, each element is the full table for P> LRP, URP or Bmsy, rows are 
#  const catch scenarios and columns are years.
# Full ymr calc is: 
# row.names(temp$LRP)
# [1] "0"    "250"  "500"  "750"  "1000" "1250" "1500" "1750" "2000" "2250"
# [11] "2500" "2750" "3000"
# row.names(t(temp$LRP))    # col.names didn't work?!
#  "2011" "2012" .... "2032"

# scenarioSubset = c("0", "500", "1000", "1500", "2000" "2250"....
fiveYears   = as.character(currYear+seq(0,5,1))
twentyYears = as.character(currYear+seq(0,20,5))
ninetyYears = as.character(currYear+seq(0,90,15))

refProbs5 = list()    # Probs for 5 years
refProbs20 = list()   # Probs for 20 years
refProbs90 = list()   # Probs for 90 years
for(i in 1:length(refProbsList))
	{
	if (projYearsNum>=5) {
		refProbs5[[i]] = refProbsList[[i]][,fiveYears]
		names(refProbs5)[i] = names(refProbsList)[i] }
	if (projYearsNum>=20) {
		refProbs20[[i]] = refProbsList[[i]][,twentyYears]
		names(refProbs20)[i] = names(refProbsList)[i] }
	if (projYearsNum>=90) {
		refProbs90[[i]] = refProbsList[[i]][,ninetyYears]
		colnames(refProbs90[[i]]) =  as.numeric(colnames(refProbs90[[i]])) - currYear
		names(refProbs90)[i] = names(refProbsList)[i] }
	}

# B0 Reference points, not doing moving window here yet 
#  (could move this to scape at some point):

B0refLevels=c(0.2, 0.4, 0.5, 0.7)
B0refNames = paste("B0", B0refLevels, sep="")
refPointsB0List = refPointsB0()     # Above two lines are defaults

refProbsB0List = calc.refProbs(refPlist = refPointsB0List)
# That's a list, each element is the full table for P> each ref point,
#  rows are const catch scenarios and columns are years.
# Check, should get:
# row.names(temp$B00.2)
# [1] "0"    "250"  "500"....
# row.names(t(temp$B00.2))      colnames(...) works
#  "2011" "2012" .... "2101"

# scenarioSubset = c("0", "500", "1000", "1500", "2000" "2250"....

refProbsB05 = list()    # Probs for 5 years
refProbsB020 = list()   # Probs for 20 years
refProbsB090 = list()   # Probs for 90 years
for(i in 1:length(refProbsB0List))
	{
	if (projYearsNum>=5) {
		refProbsB05[[i]] = refProbsB0List[[i]][,fiveYears]
		names(refProbsB05)[i] = names(refProbsB0List)[i] }
	if (projYearsNum>=20) {
		refProbsB020[[i]] = refProbsB0List[[i]][,twentyYears]
		names(refProbsB020)[i] = names(refProbsB0List)[i] }
	if (projYearsNum>=90) {
		refProbsB090[[i]] = refProbsB0List[[i]][,ninetyYears]
		colnames(refProbsB090[[i]]) =  as.numeric(colnames(refProbsB090[[i]])) - currYear
		names(refProbsB090)[i] = names(refProbsB0List)[i] }
	}
# To give 0, 15 ... as colnames for decision tables
 

# Moving window reference points from Rowan's findTarget.r code,
#  which also calculates 0.4 Bmsy and others.

refProbs3GenList = list()        # Probabilities for decision tables
               #  Will include 0.4Bmsy etc. already calculated above
               #  e.g., refProbs3Gen5$'0.4Bmsy' - refProbs5$LRP  = 0
#list of targets:
Tlst = list(list(ratio=0.4,target=Bmsy.MCMC),
  list(ratio=0.8,target=Bmsy.MCMC),
  list(ratio=0.2,target=B0.MCMC),
  list(ratio=0.4,target=B0.MCMC),
  list(ratio=0.5,target=currentMCMC$B),
  list(ratio=0.7,target=currentMCMC$B))
names(Tlst)=c("0.4Bmsy","0.8Bmsy","0.2B0","0.4B0","0.5Gen3","0.7Gen3")

refProbs3GenList = sapply(Tlst,function(x){sapply(currentProj$B,
  findTarget,ratio=x$ratio,target=x$target,retVal="p.hi")},
  simplify=FALSE)
refProbs3GenList = sapply(refProbs3GenList,t,simplify=FALSE) 
                                        # transpose matrices
refProbs3Gen5 = list()    # Probs for 5 years
refProbs3Gen90 = list()   # Probs for 90 years

for(i in 1:length(refProbs3GenList))
	{
	if (projYearsNum>=5) {
		refProbs3Gen5[[i]] = refProbs3GenList[[i]][,fiveYears]
		names(refProbs3Gen5)[i] = names(refProbs3GenList)[i] }
	if (projYearsNum>=90) {
		refProbs3Gen90[[i]] = refProbs3GenList[[i]][,ninetyYears]
		colnames(refProbs3Gen90[[i]]) =  as.numeric(colnames(refProbs3Gen90[[i]])) - currYear
		names(refProbs3Gen90)[i] = names(refProbs3GenList)[i] }
	}
# To give 0, 15 ... as colnames for decision tables

# Also calculate number of years to reach reference target points
#  with a specified confidence, 0.5, 0.8 and 0.95
Ttab0.5 = sapply(Tlst,function(x){sapply(currentProj$B,findTarget,ratio=x$ratio,target=x$target,conf=0.5,retVal="N")})
Ttab0.8 = sapply(Tlst,function(x){sapply(currentProj$B,findTarget,ratio=x$ratio,target=x$target,conf=0.8,retVal="N")})
Ttab0.95 = sapply(Tlst,function(x){sapply(currentProj$B,findTarget,ratio=x$ratio,target=x$target,conf=0.95,retVal="N")})

# Need to calculate exploitation rates over time for MCMC (MPD's are
#  included in currentRes, but nothing in currentMCMC. Going to add
#  currentMCMC$U to currentMCMC. After doing this realised it was
#  sort of done in popScapeRuns2.r, but only internally for plotting
#  figures.

if(!is.na( currentRes$B$Y[length(currentRes$B$Y)] )) stop("Check
  catch =   and  currentMCMC$U =     in run-masterMCMC.Snw") 
catch = currentRes$B$Y[-length(currentRes$B$Y)]   # take off final NA
names(catch) = years[-length(years)]
   
currentMCMC$U = currentMCMC$VB[,-dim(currentMCMC$VB)[2]] # Don't want                                        # final, as no catch
names.cmu = names(currentMCMC$U)
currentMCMC$U = t(apply(currentMCMC$U, 1, function(x,y){ y/x }, y=catch))    # Need transpose to get right way round again
names(currentMCMC$U) = names.cmu 
# So currentMCMC$U is now exploitation rate for MCMC output.
upenult.MCMC = currentMCMC$U[,as.character(currYear-1)]
umax.MCMC = apply(currentMCMC$U, 1, max)

# Catch for last five years of data:
if( diff(range(rev(catch)[1:2])) > 0 ) 
   { stop("lastFiveCatch in run-masterMCMC.Snw assumes final year 
       equals penultimate, but this isn't the case here so fix it") }
num.recentCatchYears = 5
recentCatch = rev(rev(catch)[2:(2+num.recentCatchYears-1)])
              # The last num.recentCatchYears without the final year
              #  as have assumed that's not real data
recentCatchMean = mean(recentCatch)
   
# u.MCMC.med = apply(currentMCMC$U, 2, median)  # median for each year
# For snail plots:
currentMCMC$UoverUmsy = apply(currentMCMC$U, 2, function(x,y){ x/y },  y=umsy.MCMC)    # No transpose
UoverUmsy.med = apply(currentMCMC$UoverUmsy, 2, median)
#  qtab(currentMCMC$UoverUmsy[,"2010"], dig=3 )    agrees with values
#   below in the table

currentMCMC$BoverBmsy = apply(currentMCMC$B, 2, function(x,y){ x/y },  y=Bmsy.MCMC)    # No transpose, also agrees with table below
BoverBmsy.med = apply(currentMCMC$BoverBmsy, 2, median)

# Did this to check MPD's closely matched the medians, they more or 
#  less do:
# plot(apply(currentMCMC$U, 2, median))
# points(currentRes$B$U, col="red")

# For SARA need to calculate Z = M+F = M-log(1-u), so have to do for
#  females and males. Work it out for each MCMC draw, then get the 
#  quantiles from the resulting 1000 values. But if M fixed then
#  just have u to worry about.

# Estimate M:
# Z1 = currentMCMC$P[,"M_1"] - log(1 - upenult.MCMC)
# quantile(Z1, p=c(0.05, 0.50, 0.95))
# Z2 = currentMCMC$P[,"M_2"] - log(1 - upenult.MCMC)
# quantile(Z2, p=c(0.05, 0.50, 0.95))

# Fix M, for females (males the same if fixed values the same):
# Z1 = M1.prior[7] - log(1 - upenult.MCMC)
# quantile(Z1, p=c(0.05, 0.50, 0.95))

quantiles = c(0.05, 0.5, 0.95)      # for tables
# Next was for saving to an .RData file to load into 
#  ../../../POPdeterminR/POPdeterminR.r   to run deterministic model.
# First give variable names that match my write up, then save them 
#  all.
# First set are to be used as input, second set as confirmation.
# For YMR, for now commenting out ones from MCMC.

A = max(currentRes$Sel[,"Age"])
T = diff(range(currentRes$B[,"Year"]))+1       # =72
Ct = currentRes$B$Y[-length(currentRes$B$Y)]    # Takes off 2011 value
# years = currentRes$B[,"Year"]    # moving earlier
ages = sort(unique(currentRes$CAc$Age))

selgeqComm = currentRes$Sel[currentRes$Sel$"Series" == "Gear 1",] 
    # comm sel, selgeq4 for POP, presumably woudl be 6 for YMR as
    #  5 surveyrs, so just write Comm
mat = currentRes$Sel[currentRes$Sel$"Series" == "Maturity" &
       currentRes$Sel$"Sex" == "Female",]      # Female maturity
# M1 = currentMCMC$P[1,"M_1"]           # MPD is first line of MCMC
# M2 = currentMCMC$P[1,"M_2"]           # MPD is first line of MCMC
Rt = currentRes$B$R[-length(currentRes$B$R)]   
                                        # Remove final NA for 2011,
Rt.mpd = Rt       # don't think Rt gets used elsewhere, but leave
                  #  it valid just in case.
# For confirmation:
# R0.mpd = currentMCMC$P[1,"R_0"] #Matches numbers from Ro_So_VB.pst,
                                  # but wasn't going to use that 
                                  #  before?
# h.mpd = currentMCMC$P[1,"h"]
Nats.mpd = currentRes$N
ut.mpd = currentRes$B$U[-length(currentRes$B$U)]  
                                  # remove final NA for 2011
Bt.mpd = currentRes$B$SB
B0.mpd = Bt.mpd[1]       #****CHANGE*** if change init cdts.
Vt.mpd = currentRes$B$V
logRecDev.mpd = currentRes$Dev$Annual
# Also equals currentRes$extra$parameters$log_RecDev from Rowan's 'extra' sublist  in currentRes.

# AME deleted lots of commented out code. 20th August 2012.

@ 

<<plottingFigs, results=hide, echo=FALSE>>=
# Moved from above, as now have currentMCMC$U calcs
# plt.idx( currentRes$Survey,main="Survey Indices") # wasn't called 
#  in plt.mpdGraphs. Doing it here spits out SD of standardised 
#  residuals also. May be useful for iterative reweighting?


plt.mcmcGraphs( currentMCMC, currentProj, save=TRUE, 
                 plotPolicies = names(currentProj$Y[1:6]),
                 onePolicy = names(currentProj$Y[2]) )
              # Change policy options if want other catch policies 
              #  shown. Set up for length(plotPolicies)=6
              # See help for other options.
# close.allWin()


# function to use for priors in MPD table. Must read in a vector of 
#  length, and outputs it in the format for the table.
ptab = function(xx) 
  { print(paste(c(xx[1], " & [", xx[2], ",", xx[3], "] & ", 
          xx[4], " & [", xx[5], ",", xx[6], "] & ", xx[7]),
          sep="", collapse="")) 
  }
qtab = function(xx.MCMC, dig=0)     # dig is number of dec places
  { print(paste( c( prettyNum(round(quantile(xx.MCMC, 0.05), 
                                  digits=dig), big.mark=","), 
         " & ", prettyNum(round(quantile(xx.MCMC, 0.50), digits=dig),
                                  big.mark=","),
         " & ", prettyNum(round(quantile(xx.MCMC, 0.95), digits=dig),
                                  big.mark=",")), 
         sep="", collapse=""))
  }  

# For q_i in table, values can vary between runs, so set to number
#  of significant digits. NOT USED, just doing 4 decimal places
#  for all. 
# sapply(signif(x,3), sprintf, fmt="%#.3g")   # try that for 
#  1.3001  to be 1.300.   Haven't played with yet.
qqtab = function(xx.MCMC, dig=3)     # dig is number sig digits
  { print(paste( c( prettyNum(signif(quantile(xx.MCMC, 0.05), 
                                  digits=dig), big.mark=","), 
        " & ", prettyNum(signif(quantile(xx.MCMC, 0.50), digits=dig),
                                  big.mark=","),
        " & ", prettyNum(signif(quantile(xx.MCMC, 0.95), digits=dig),
                                  big.mark=",")), 
         sep="", collapse=""))
  }  



# not saving for YMR for now (don't have all these variables, though
#  just MPDs so don't need MCMC output).  [These were from MCMC's]
# save(A, T, Ct, selgeqComm, mat, M1, M2, Rt, R0.mpd, h.mpd, Nats.mpd, ut.mpd,  Bt.mpd, B0.mpd, Vt.mpd, logRecDev.mpd, file="run23values.RData")
 # 
# save.image(file="run23all.RData")

# See popScape2.r for pairs plots, from:
# Copy and run this for pairs plots        to
# text(currentRes$B$SB, currentRes$B$U, 1:72)


# Want to report the mean of the median recruitments for past and
#  projections.
recMed = apply(currentMCMC$R, 2, median)
meanRecMed = mean(recMed)
# Do for one policy
# recProjMed1500 = apply(currentProj$R$'1500', 2, median)
# meanRecProjMed1500 = mean(recProjMed1500)


@ 

% Comment out table parest for now (Priors and MPD estimates - see
%  ymrrun-master.Snw), though use that as template to make a table
% of posterior statistics

% Then find and replace run *** to Estimate M for the write up.

\ymrfig{traceParams}{MCMC traces for the primary estimated parametersfor run \Sexpr{model.name}. Grey lines show the \Sexpr{num.MCMC} samples for each parameter, solid lines show the cumulative median (up to that sample), and dashed lines show the cumulative 2.5 and 97.5 quantiles.  Red circles are the MPD estimates. }
% Subscripts 1 to 5 are for surveys: GIG historical, QCS synoptic, QCS shrimp, WCHQ synoptic and WCVI synoptic. Subscript 6 is the commercial fishery.}   % for the base run "Estimate M \& h".

\ymrfig{splitChain}{Diagnostic plot for run \Sexpr{model.name}, obtained by dividing the MCMC chain of \Sexpr{num.MCMC} MCMC samples into three segments, and overplotting the cumulative distributions of the first segment (green), second segment (red) and final segment (blue).}
% overplotting the cumulative distributions, removing the first 100, then plotting the cumulative distributions for samples 101-400 (green), 301-700 (red) and 701-1000 (blue). }

\ymrfig{pairs1}{Pairs plot of \Sexpr{num.MCMC} MCMC samples for first six parameters for run \Sexpr{model.name}.}

% Need a switch here along the lines of
%  # if(length(use.Pnames) > xx)     if not having 3 figures,
%  as plt.mcmcGraphs won't produce pairs2 or pairs3 (and will go
%  up to pairs5). May not be easily generalisable, given
%  Latex will depend on R - but can just comment out or add more in.
% This didn't work, so just do manually.
% <<pairsPlots, results=tex, echo=FALSE>>=
% if(length(use.Pnames) > 6 )
%   { print(paste(" \\ymrfig{pairs2}{Pairs plot for second six parameters.}")) }
% @ 

\ymrfig{pairs2}{Pairs plot for second six parameters.}

% \ymrfig{pairs3}{Pairs plot of \Sexpr{num.MCMC} MCMC samples for third set of parameters for run \Sexpr{model.name}.}

% \ymrfig{pairs4}{Pairs plot of \Sexpr{num.MCMC} MCMC samples for ** parameters for run \Sexpr{model.name}.}

% \ymrfig{pairs5}{Pairs plot of \Sexpr{num.MCMC} MCMC samples for ** parameters for run \Sexpr{model.name}.}

\ymrfig{traceBiomass}{MCMC traces for female spawning biomass estimates at five-year intervals for run \Sexpr{model.name}.  Note that vertical scales are different for each plot (to show convergence of the MCMC chain, rather than absolute differences in annual values). Grey lines show the \Sexpr{num.MCMC} samples for each parameter, solid lines show the cumulative  median (up to that sample), and dashed lines show the cumulative  2.5 and 97.5 quantiles.  Red circles are the MPD estimates.}

\ymrfig{traceRecruits}{MCMC traces for recruitment estimates at five-year intervals for run \Sexpr{model.name}. Note that vertical scales are different for each plot (to show convergence of the MCMC chain, rather than absolute differences in annual recruitment). Grey lines show the \Sexpr{num.MCMC} samples for each parameter, solid lines show the cumulative  median (up to that sample), and dashed lines show the cumulative  2.5 and 97.5 quantiles.  Red circles are the MPD estimates.}

\ymrfig{pdfParameters}{Marginal posterior densities (thick black curves) and prior density functions (thin blue curves) for the estimated parameters for run \Sexpr{model.name}. Vertical lines represent the 2.5, 50 and 97.5 percentiles, and red filled circles are the MPD estimates. [Distributions are hardwired:] For $R_0$ the prior is a uniform distribution on the range [\Sexpr{priorInput["R_0",2]}, \Sexpr{priorInput["R_0",3]}], and is at too low a value to show up on the graph. The priors for $q_g$ are uniform on a log-scale, and so the probability density function is $1/(x(b-a))$ on a linear scale (where $a$ and $b$ are the bounds on the log scale).}
% such that half of the weight of the prior distribution lies $>0.03$ [**for the parameters used in YMR], which is not obvious from the graphs. 

\clearpage

\ymrfig{selectivityMCMC}{**** MCMC selectivity figure will go here, haven't calculated yet (started in {\tt plotSelMCMC.r} and see prior calculation folder).}

\ymrfig{pdfBiomass1}{Marginal posterior densities for beginning year female spawning biomass (1000 tonnes) for years 1940-1963 for run \Sexpr{model.name}. Horizontal axes are all to same scale. Note that vertical axes are not to the same scale, but each is scaled to the peak of the density; with the area under each curve integrating to 1.0. Vertical lines are 2.5, 50 and 97.5 percentiles, and filled red circle indicates MPD value.  [**Years not generalised yet.]}

\ymrfig{pdfBiomass2}{As for Figure \ref{fig:pdfBiomass1} for years 1964-1987.}

\ymrfig{pdfBiomass3}{As for Figure \ref{fig:pdfBiomass1} for years 1988-2011.}

\ymrfig{pdfBiomass4}{As for Figure \ref{fig:pdfBiomass1} for years 2012-\Sexpr{currYear}.}

\ymrfig{pdfRecruitment1}{Marginal posterior densities for recruitment for years 1940-1963 for run \Sexpr{model.name}. Horizontal axes are all to same scale, such that large recruitments in certain large years can be seen. Note that vertical axes are not to the same scale, but each is scaled to the peak of the density; areas under each curve will integrate to 1.0. Vertical lines are 2.5, 50 and 97.5 percentiles, and filled red circle indicates MPD value. }

\ymrfig{pdfRecruitment2}{As for Figure \ref{fig:pdfRecruitment1} for years 1964-1987.}

\ymrfig{pdfRecruitment3}{As for Figure \ref{fig:pdfRecruitment1} for years 1988-2011.}

\ymrfig{pdfRecruitment4}{As for Figure \ref{fig:pdfRecruitment1} for years 2012-\Sexpr{currYear-1}.}

\ymrfig{recruitsMCMC}{Marginal posterior distribution of recruitment in 1000's of age 1 fish plotted over time for run \Sexpr{model.name}. The boxes give the 2.5, 25, 50, 75 and 97.5 percentiles from the MCMC results.}

\ymrfig{VBcatch}{Vulnerable biomass (boxplots) and commercial catch (vertical bars) over time for run \Sexpr{model.name}. Boxplots show the 2.5, 25, 50, 75 and 97.5 percentiles from the MCMC results. Catch is shown to compare its magnitude to the estimated vulnerable biomass.}

\ymrfig{exploitMCMC}{Marginal posterior distribution of exploitation rate plotted over time for run \Sexpr{model.name}. The boxes give the 2.5, 25, 50, 75 and 97.5 percentiles from the MCMC results.}



\ymrfig{BVBnorm}{Changes in $B_t / B_0$ and $V_t / V_0$ (spawning and vulnerable biomass relative to virgin levels) over time for run \Sexpr{model.name}, shown as the medians of the MCMC posteriors.}

\clearpage 

\ymrfig{snail}{Trace through time of the medians of the ratios $B_t / B_\mathrm{MSY}$ (the spawning biomass in year $t$ relative to $B_\mathrm{MSY}$) and $u_t / u_\mathrm{MSY}$ (the exploitation rate in year $t$ relative to $u_\mathrm{MSY}$) for run \Sexpr{model.name}. Blue filled circle is the starting year (\Sexpr{startYear}). Years then proceed from light grey through to dark grey with the final year (\Sexpr{currYear - 1}) as a filled red circle, and the red lines represent the 10\% and 90\% percentiles of the posterior distributions for the final year. Vertical grey lines indicate the provisional limit and upper stock reference points of 0.4$B_\mathrm{MSY}$ and 0.8$B_\mathrm{MSY}$, and horizontal grey line indicates $u_\mathrm{MSY}$.}

\ymrfig{Bproj}{Projected biomass under different constant catch strategies for run \Sexpr{model.name}~(boxplots show the 2.5, 25, 50, 75 and 97.5 percentiles from the MCMC results). For each of the \Sexpr{num.MCMC} samples from the MCMC posterior, the model was run forward in time (red) with a constant catch, and recruitment was simulated from the stock-recruitment function with lognormal error (see equation F.24). For reference, the average catch over the last \Sexpr{num.recentCatchYears} years (\Sexpr{ as.numeric(names(recentCatch)[1])}-\Sexpr{as.numeric(rev(names(recentCatch))[1])}) is \Sexpr{round(recentCatchMean, dig=0)}~t.}

\ymrfig{Rproj}{Projected recruitments under different constant catch strategies for run \Sexpr{model.name}~(boxplots show the 2.5, 25, 50, 75 and 97.5 percentiles from the MCMC results). This shows that the random projected recruitments are fairly similar from year-to-year, without the large recruitment events that are seen in the past. While individual MCMC simulations may have occasional large recruitments, this will not happen for a particular year for all MCMC simulations concurrently, which did happen in the past (so, in particular, the lowest estimates of recruitment were still high).}
% xx = apply(currentProj$R$'0', 2, max)
% summary(xx)
  
\ymrfig{RprojOnePolicy}{Projected recruitments for just ** constant catch strategy (to go into SAR) for run \Sexpr{model.name}~(boxplots show the 2.5, 25, 50, 75 and 97.5 percentiles from the MCMC results). This shows that the random projected recruitments are fairly similar from year-to-year, without the large recruitment events that are seen in the past. While individual MCMC simulations may have occasional large recruitments, this will not happen for a particular year for all MCMC simulations concurrently, which did happen in the past (so, in particular, the lowest estimates of recruitment were still high). The mean of the median historical recruitments is \Sexpr{round(meanRecMed, digits=0)}.}  
%, whereas the mean of the median projected recruitments is *** } 
% xx = apply(currentProj$R$'1500', 2, median)
% mean(xx)   
% yy = apply(currentMCMC$R, 2, median)
% mean(yy)


\clearpage     % to get tables at end

% To get , in for 1,000s do   big.mark='','' in the following
%      print(xtable(refProbs5$URP), format.args=list(big.mark=","))
% Would have to make the table in R to then use xtable, but then
%  might be tricky to fix the number of sigdigs. Just put in commas
%  for final version.

\begin{table}[tp]
\centering
\caption{\label{tab:MCMCpar} 
Summary statistics of MCMC results for estimated parameters for run \Sexpr{model.name}. Parameters are defined in Appendix F. Except for $M_1$ and $M_2$, subscripts 1 to \Sexpr{Nsurv} correspond to the fishery-independent surveys, and subscript \Sexpr{Nsurv+1} to the commercial fishery.}
% Fiddling for now, need to generalise. ***
\begin{tabular}{lrrr} 
\hline
Parameter & \multicolumn{3}{c}{Percentile}\\
\cline{2-4}
 & 5\% & 50\% & 95\% \\
\hline 
$R_0$    & \Sexpr{qtab(currentMCMC$P$R_0)} \\
$M _ 1$  & \Sexpr{ if(length(currentMCMC$P$M_1) > 0) qtab(currentMCMC$P$M_1,dig=4) else  print(paste( "- & - & -", collapse = "")) } \\
$M _ 2$  & \Sexpr{ if(length(currentMCMC$P$M_2) > 0) qtab(currentMCMC$P$M_2,dig=4)  else  print(paste( "- & - & -", collapse = "")) } \\
$h$      & \Sexpr{ if(length(currentMCMC$P$h) > 0) qtab(currentMCMC$P$h, dig=3)  else  print(paste( "- & - & -", collapse = "")) } \\
$q_1$      & \Sexpr{qtab(currentMCMC$P$q_1, dig=4)} \\
$q_2$      & \Sexpr{qtab(currentMCMC$P$q_2, dig=4)} \\
$q_3$      & \Sexpr{qtab(currentMCMC$P$q_3, dig=4)} \\
$q_4$      & \Sexpr{qtab(currentMCMC$P$q_4, dig=4)} \\
% $q_5$      & \Sexpr{qtab(currentMCMC$P$q_5, dig=5)} \\
$\mu_1$    & \Sexpr{qtab(currentMCMC$P$mu_1, dig=1)} \\
% $\mu_2$    & \Sexpr{qtab(currentMCMC$P$mu_2, dig=1)} \\
$\mu_4$    & \Sexpr{qtab(currentMCMC$P$mu_4, dig=1)} \\
$\Delta_1$ & \Sexpr{qtab(currentMCMC$P$Delta_1, dig=2)} \\
% $\Delta_2$ & \Sexpr{qtab(currentMCMC$P$Delta_2, dig=2)} \\ 
$\Delta_4$ & \Sexpr{qtab(currentMCMC$P$Delta_4, dig=2)} \\
$\log v_{1L}$  & \Sexpr{qtab(currentMCMC$P$"log v_1L", dig=2)} \\
% $\log v_{2L}$  & \Sexpr{qtab(currentMCMC$P$"log v_2L", dig=2)} \\
$\log v_{4L}$  & \Sexpr{qtab(currentMCMC$P$"log v_4L", dig=2)} \\
\hline
\end{tabular}	
\end{table}



\begin{table}[tp]
\centering
\caption{\label{tab:MCMCderived} MCMC-derived quantities for run \Sexpr{model.name}, from each sample of the MCMC posterior. A maximum exploitation rate $u_{max}$ is calculated for each sample as the maximum exploitation rate from \Sexpr{startYear}-\Sexpr{as.numeric(rev(names(currentMCMC$U[1,]))[1])}. For reference, the average catch over the last \Sexpr{num.recentCatchYears} years (\Sexpr{ as.numeric(names(recentCatch)[1])}-\Sexpr{as.numeric(rev(names(recentCatch))[1])}) is \Sexpr{round(recentCatchMean, dig=0)}~t.}
\medskip
\begin{tabular}{lrrr} 
\hline
Value & \multicolumn{3}{c}{Percentile}\\
\cline{2-4}
 & 5\% & 50\% & 95\% \\
\hline 
 & & & \\
& \multicolumn{3}{c}{From model output}\\
$B_0$                  & \Sexpr{qtab(B0.MCMC)} \\
$V_0$                  & \Sexpr{qtab(VB0.MCMC)} \\
$B_{\Sexpr{currYear}}$             & \Sexpr{qtab(Bcurr.MCMC)} \\
$V_{\Sexpr{currYear}}$             & \Sexpr{qtab(VBcurr.MCMC)} \\

$B_{\Sexpr{currYear}} / B_0$       & \Sexpr{qtab(Bcurr.MCMC / B0.MCMC, dig=3)} \\
$V_{\Sexpr{currYear}} / V_0$     & \Sexpr{qtab(VBcurr.MCMC / VB0.MCMC, dig=3)} \\

$u_{\Sexpr{currYear-1}}$             & \Sexpr{qtab(upenult.MCMC, dig=3)} \\
$u_\mathrm{max}$       & \Sexpr{qtab(umax.MCMC, dig=3)} \\
\hline
 & & & \\
& \multicolumn{3}{c}{MSY-based quantities}\\
$0.4 B_\mathrm{MSY}$   &  \Sexpr{qtab(0.4*Bmsy.MCMC)} \\
$0.8 B_\mathrm{MSY}$   &  \Sexpr{qtab(0.8*Bmsy.MCMC)} \\
$B_\mathrm{MSY}$       &  \Sexpr{qtab(Bmsy.MCMC)} \\
$B_\mathrm{MSY} / B_0$ &  \Sexpr{qtab(Bmsy.MCMC / B0.MCMC, dig=3)} \\
$B_{\Sexpr{currYear}} / B_\mathrm{MSY}$ & \Sexpr{qtab(Bcurr.MCMC / Bmsy.MCMC, dig=3)} \\

$\mathrm{MSY}$                    & \Sexpr{qtab(msy.MCMC)} \\
$u_\mathrm{MSY}$       & \Sexpr{qtab(umsy.MCMC, dig=3)} \\
$u_{\Sexpr{currYear-1}} / u_\mathrm{MSY}$ & \Sexpr{qtab(upenult.MCMC / umsy.MCMC, dig=3)} \\

$V_\mathrm{MSY}$       & \Sexpr{qtab(VBmsy.MCMC)} \\
$V_\mathrm{MSY} / V_0$ & \Sexpr{qtab(VBmsy.MCMC / VB0.MCMC, dig=3)} \\
\hline
\end{tabular}	
\end{table}


<<tables, results=tex, echo=FALSE>>=
# xtable(matrix( c( hbigeye100$counts), ncol=4, byrow=TRUE), digits = 0, caption="Counts for 1-100, showing every 4th seems to be higher, with every 8th being way higher.")

tabdigits = 2      # number of decimal places to give
print(xtable(refProbs5$LRP, caption=eval(paste("Decision table concerning the limit reference point $0.4 \\Bmsy$ for 1-5 year projections for run ", model.name, " for a range of constant catch strategies (in tonnes). Values are P$(B_t > 0.4 \\Bmsy)$, i.e.~the probability of the spawning biomass at the start of year $t$ being greater than the limit reference point. The probabilities are based on the MCMC posterior distributions of $B_t$ and $\\Bmsy$, and are rounded to two decimal places. For reference, the average catch over the last ", num.recentCatchYears, " years (", as.numeric(names(recentCatch)[1]), "-", as.numeric(rev(names(recentCatch))[1]), ") is ", round(recentCatchMean, dig=0), "~t.", sep="")), label="tab:LRP5", digits=tabdigits), caption.placement="top") 
# it didn't like \Sexpr in caption="" - need eval(paste

print(xtable(refProbs5$URP, caption=eval(paste("Decision table for the upper reference point $0.8 \\Bmsy$ for 1-5 year projections for run ", model.name, ", such that values are P$(B_t > 0.8 \\Bmsy)$. For reference, the average catch over the last ", num.recentCatchYears, " years (", as.numeric(names(recentCatch)[1]), "-", as.numeric(rev(names(recentCatch))[1]), ") is ", round(recentCatchMean, dig=0), "~t.", sep="")), label="tab:URP5", digits=tabdigits), caption.placement="top")

# print(xtable(refProbs5$Bmsy, caption="Decision table for MSY for 1-5 year projections for run MODEL.NAME, such that values are P$(B_t > \\Bmsy)$.", label="tab:Bmsy5", digits=tabdigits), caption.placement="top")

print(xtable(refProbsB05$B00.2, caption=eval(paste("Decision table for the alternative limit reference point $0.2 B_0$ for 1-5 year projections for run ", model.name, ", such that values are P$(B_t > 0.2 B_0)$. For reference, the average catch over the last ", num.recentCatchYears, " years (", as.numeric(names(recentCatch)[1]), "-", as.numeric(rev(names(recentCatch))[1]), ") is ", round(recentCatchMean, dig=0), "~t.", sep="")), label="tab:B00.2.5yr", digits=tabdigits), caption.placement="top")

print(xtable(refProbsB05$B00.4, caption=eval(paste("Decision table for the alternative upper reference point $0.4 B_0$ for 1-5 year projections for run ", model.name, " such that values are P$(B_t > 0.4 B_0)$. For reference, the average catch over the last ", num.recentCatchYears, " years (", as.numeric(names(recentCatch)[1]), "-", as.numeric(rev(names(recentCatch))[1]), ") is ", round(recentCatchMean, dig=0), "~t.", sep="")), label="tab:B00.4.5yr", digits=tabdigits), caption.placement="top")

print(xtable(refProbs3Gen5$'0.5Gen3', caption=eval(paste("NOT CHECKED FROM HERE ONWARDS** Decision table for probabilities of satisfying the criterion of $\\leq 50 \\%$ decline over three generations, for 1-5 year projections for run MODEL.NAME. Three generations is 90 years, and since $B_0$ is the estimated spawning biomass in 1940 and projections here are only up to 5 years, the probabilites here are simply equal to P$(B_t > 0.5 B_0)$. For reference, the average catch over the last ", num.recentCatchYears, " years (", as.numeric(names(recentCatch)[1]), "-", as.numeric(rev(names(recentCatch))[1]), ") is ", round(recentCatchMean, dig=0), "~t.", sep="")), label="tab:0.5Gen3.5yr", digits=tabdigits), caption.placement="top")

print(xtable(refProbs3Gen5$'0.7Gen3', caption=eval(paste("Decision table for probabilities of satisfying the criterion of $\\leq 30 \\%$ decline over three generations, for 1-5 year projections for run MODEL.NAME. Three generations is 90 years, and since $B_0$ is the estimated spawning biomass in 1940 and projections here are only up to 5 years, the probabilites here are simply equal to P$(B_t > 0.7 B_0)$. For reference, the average catch over the last ", num.recentCatchYears, " years (", as.numeric(names(recentCatch)[1]), "-", as.numeric(rev(names(recentCatch))[1]), ") is ", round(recentCatchMean, dig=0), "~t.", sep="")), label="tab:0.7Gen3.5yr", digits=tabdigits), caption.placement="top")
             
           

# print(xtable(refProbsB05$B00.5, caption="Decision table for reference point $0.5 B_0$ for 1-5 year projections for run MODEL.NAME, such that values are P$(B_t > 0.5 B_0)$.", label="tab:B00.5.5yr", digits=tabdigits), caption.placement="top")

# print(xtable(refProbsB05$B00.7, caption="Decision table for reference point $0.7 B_0$ for 1-5 year projections for run MODEL.NAME, such that values are P$(B_t > 0.7 B_0)$.", label="tab:B00.7.5yr", digits=tabdigits), caption.placement="top")

# print(xtable(refProbs90$LRP, caption="Decision table for the limit reference point $0.4 \\Bmsy$ for every 15th year (starting from 2011) of 90-year projections for run MODEL.NAME, such that values are P$(B_t > 0.4 \\Bmsy)$.", label="tab:LRP90", digits=tabdigits), caption.placement="top") 

# print(xtable(refProbs90$URP, caption="Decision table for the upper reference point $0.8 \\Bmsy$ for every 15th year of 90-year projections for run MODEL.NAME, such that values are P$(B_t > 0.8 \\Bmsy)$.", label="tab:URP90", digits=tabdigits), caption.placement="top")

# print(xtable(refProbsB090$B00.2, caption="Decision table for the alternative limit reference point $0.2 B_0$ for 90-year projections for run MODEL.NAME, such that values are P$(B_t > 0.2 B_0)$.", label="tab:B00.2.90yr", digits=tabdigits), caption.placement="top")

# print(xtable(refProbsB090$B00.4, caption="Decision table for the alternative upper reference point $0.4 B_0$ for 90-year projections for run MODEL.NAME, such that values are P$(B_t > 0.4 B_0)$.", label="tab:B00.4.90yr", digits=tabdigits), caption.placement="top")

# print(xtable(refProbs3Gen90$'0.5Gen3', caption="Decision table for probabilities of satisfying the criterion of $\\leq 50 \\%$ decline over three generations for 90-year projections for run MODEL.NAME. The probabilites are P$(B_t > 0.5 B_{t-90})$.", label="tab:0.5Gen3.90yr", digits=tabdigits), caption.placement="top")

# print(xtable(refProbs3Gen90$'0.7Gen3', caption="Decision table for probabilities of satisfying the criterion of $\\leq 30 \\%$ decline over three generations for 90-year projections for run MODEL.NAME. The probabilites are P$(B_t > 0.7 B_{t-90})$.", label="tab:0.7Gen3.90yr", digits=tabdigits), caption.placement="top")

print(xtable(Ttab0.5, caption="Estimated time (years) to be above each reference point or achieve each target with a probability of 50\\%, for each constant catch strategy and for run MODEL.NAME. An estimated time of 0 means that the condition is currently satisfied and remains so over the 90-year projection; an estimated time of 90 means that the condition never becomes satisfied over the 90-year projection. A further condition is that the probability of satisfying the condition must increase for two consecutive years. Columns respectively correspond to reference points $0.4 \\Bmsy, 0.8 \\Bmsy, 0.2 B_0, 0.4 B_0$ and to the criteria of $\\leq 50 \\%$ decline and $\\leq 30 \\%$ decline over three generations.", label="tab:Ttab0.5", digits=0), caption.placement="top")

print(xtable(Ttab0.8, caption="Estimated time to be above each reference point or achieve each target with a probability of 80\\%, for each constant catch strategy and for run MODEL.NAME. See Table \\ref{tab:Ttab0.5} for column definitions.", label="tab:Ttab0.8", digits=0), caption.placement="top")

print(xtable(Ttab0.95, caption="Estimated time to be above each reference point or achieve each target with a probability of 95\\%, for each constant catch strategy and for run MODEL.NAME. See Table \\ref{tab:Ttab0.5} for column definitions.", label="tab:Ttab0.95", digits=0), caption.placement="top")




# print(xtable(refProbsB090$B00.5, caption="Decision table for reference point $0.5 B_0$ for 90-year projections for run MODEL.NAME, such that values are P$(B_t > 0.5 B_0)$.", label="tab:B00.5.90yr", digits=tabdigits), caption.placement="top")

# print(xtable(refProbsB090$B00.7, caption="Decision table for reference point $0.7 B_0$ for 90-year projections for run MODEL.NAME, such that values are P$(B_t > 0.7 B_0)$.", label="tab:B00.7.90yr", digits=tabdigits), caption.placement="top")




# print(xtable(refProbs20$LRP, caption="Decision table for the lower reference point $0.4 \\Bmsy$ for every 5th year of 20-year projections for run MODEL.NAME, such that values are P$(B_t > 0.4 \\Bmsy)$.", label="tab:LRP20", digits=tabdigits), caption.placement="top")

# print(xtable(refProbs20$URP, caption="Decision table for the upper reference point $0.8 \\Bmsy$ for every 5th year of 20-year projections for run MODEL.NAME, such that values are P$(B_t > 0.8 \\Bmsy)$.", label="tab:URP20", digits=tabdigits), caption.placement="top")

# print(xtable(refProbs20$Bmsy, caption="Decision table for $\\Bmsy$ for every 5th year of 20-year projections for run MODEL.NAME, such that values are P$(B_t > \\Bmsy)$.", label="tab:Bmsy20", digits=tabdigits), caption.placement="top")

@ 

<<savingTables, results=hide, echo=FALSE>>=
# see saving.r in YMR11 for details of tables. Or just look
#  at each one, as they're not that long.  # refProbs3Gen90
save(refProbs3Gen5, Ttab0.5, Ttab0.8, Ttab0.95,  file=paste(model.name, "Tables.RData", sep=""))
@ 


\end{document}

% CUT HERE 

